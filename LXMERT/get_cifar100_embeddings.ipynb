{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebcf31be-2c72-4f3b-8e8e-4d4df20eec01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from processing_image import Preprocess\n",
    "from modeling_frcnn import GeneralizedRCNN\n",
    "from utils import Config\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f639b7-5fa5-4e11-9dde-e594c519a460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Image\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a96d43-0d18-4750-893b-7b51ded57ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "561d4619-ad18-467f-8412-a020e7c69011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22185457-c800-4aaa-9283-77c6414e1bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n",
      "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /nas/home/bchidamb/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\n",
      "All model checkpoint weights were used when initializing GeneralizedRCNN.\n",
      "\n",
      "All the weights of GeneralizedRCNN were initialized from the model checkpoint at unc-nlp/frcnn-vg-finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GeneralizedRCNN for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load models and model components\n",
    "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "frcnn_cfg.model.DEVICE = device\n",
    "\n",
    "frcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=frcnn_cfg).to(device)\n",
    "\n",
    "image_preprocess = Preprocess(frcnn_cfg)\n",
    "\n",
    "# bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "# visualbert_vqa = VisualBertForQuestionAnswering.from_pretrained(\"uclanlp/visualbert-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5973abc-974e-4b1a-959f-64fc7c191ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar100 (/nas/home/bchidamb/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb44005d77a344ae81610d3aa7473b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar10_data = load_dataset(\"cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5b6644-b809-403c-9ce8-9077529028fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = cifar10_data[\"train\"]\n",
    "test_data = cifar10_data[\"test\"]\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211a7367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=32x32 at 0x7FBE8CEBAA70>, 'fine_label': 19, 'coarse_label': 11}\n",
      "On idx 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('obj_ids',\n",
       "              tensor([[ 364,  364,  364,  540,  540,  364,  364,  540,  364,  540,  540,  364,\n",
       "                        540,  540,  364,  540,  540,  364,  364,  540,  540,  540,  540,  956,\n",
       "                        956,  956,  540,  540,  956,  540,  956,  956,  956, 1021,  540,  956]])),\n",
       "             ('obj_probs',\n",
       "              tensor([[0.7614, 0.6832, 0.6828, 0.6101, 0.5694, 0.5662, 0.5573, 0.5517, 0.5334,\n",
       "                       0.5088, 0.5017, 0.4458, 0.4230, 0.3948, 0.3843, 0.3834, 0.3656, 0.3483,\n",
       "                       0.3362, 0.3353, 0.2942, 0.2785, 0.2744, 0.2637, 0.2476, 0.2122, 0.2046,\n",
       "                       0.1994, 0.1621, 0.1527, 0.1514, 0.1427, 0.1417, 0.1307, 0.1284, 0.1181]])),\n",
       "             ('attr_ids',\n",
       "              tensor([[210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
       "                       210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210, 210,\n",
       "                       210, 210, 210, 210, 210, 210, 210, 210]])),\n",
       "             ('attr_probs',\n",
       "              tensor([[0.9035, 0.9109, 0.8695, 0.9571, 0.9681, 0.6846, 0.7220, 0.9533, 0.7736,\n",
       "                       0.9649, 0.9797, 0.7859, 0.9684, 0.9767, 0.8463, 0.9884, 0.9713, 0.9210,\n",
       "                       0.7962, 0.9275, 0.9902, 0.9618, 0.9688, 0.9787, 0.9747, 0.8985, 0.9886,\n",
       "                       0.9863, 0.9804, 0.9556, 0.9294, 0.9647, 0.9797, 0.8273, 0.9420, 0.9231]])),\n",
       "             ('boxes',\n",
       "              tensor([[[7.5259e+00, 3.9211e+00, 1.4142e+01, 1.6666e+01],\n",
       "                       [6.3170e+00, 3.0379e+00, 1.5887e+01, 1.5757e+01],\n",
       "                       [8.0848e+00, 2.7029e+00, 1.4525e+01, 1.4531e+01],\n",
       "                       [4.7309e+00, 0.0000e+00, 2.6498e+01, 1.5900e+01],\n",
       "                       [6.7232e+00, 0.0000e+00, 2.9704e+01, 1.3531e+01],\n",
       "                       [1.5763e+01, 7.4062e-01, 2.2969e+01, 1.3265e+01],\n",
       "                       [1.4357e+01, 2.3487e+00, 2.2236e+01, 1.5288e+01],\n",
       "                       [8.8099e+00, 0.0000e+00, 2.8484e+01, 2.1243e+01],\n",
       "                       [1.6358e+01, 2.4386e+00, 2.3731e+01, 1.4782e+01],\n",
       "                       [8.1007e+00, 0.0000e+00, 2.4140e+01, 2.3858e+01],\n",
       "                       [4.4514e+00, 1.5458e-01, 2.1747e+01, 1.9864e+01],\n",
       "                       [1.4095e+01, 9.7524e-01, 2.4316e+01, 1.2705e+01],\n",
       "                       [5.6535e+00, 0.0000e+00, 3.1788e+01, 1.7989e+01],\n",
       "                       [5.2333e-01, 5.6343e-02, 2.5556e+01, 1.8803e+01],\n",
       "                       [1.1669e+01, 2.4387e-01, 2.4917e+01, 1.8525e+01],\n",
       "                       [3.8856e+00, 1.5453e+00, 2.5825e+01, 2.6737e+01],\n",
       "                       [9.5510e+00, 2.7001e+00, 3.0417e+01, 2.6477e+01],\n",
       "                       [1.2296e+01, 3.4072e-01, 2.6306e+01, 2.3203e+01],\n",
       "                       [1.3725e+01, 3.8797e+00, 2.4671e+01, 1.6952e+01],\n",
       "                       [1.3602e+01, 3.0905e+00, 3.1791e+01, 2.4691e+01],\n",
       "                       [4.0391e-01, 2.6486e+00, 2.3089e+01, 2.3600e+01],\n",
       "                       [1.3422e+01, 0.0000e+00, 3.1773e+01, 1.2183e+01],\n",
       "                       [1.2022e+01, 1.0063e-01, 2.8531e+01, 2.9245e+01],\n",
       "                       [0.0000e+00, 3.2539e-01, 1.4470e+01, 2.1569e+01],\n",
       "                       [0.0000e+00, 1.7096e+00, 1.3577e+01, 2.8350e+01],\n",
       "                       [1.9709e-01, 2.3017e-02, 3.1780e+01, 1.1086e+01],\n",
       "                       [2.3348e-01, 3.2488e+00, 1.6612e+01, 2.3682e+01],\n",
       "                       [2.5972e+00, 3.3087e-01, 1.8318e+01, 2.3824e+01],\n",
       "                       [3.9969e-01, 2.7229e+00, 1.8242e+01, 3.0964e+01],\n",
       "                       [1.1549e+01, 4.6945e+00, 2.6528e+01, 3.0594e+01],\n",
       "                       [7.9767e-02, 1.3523e+01, 2.8189e+01, 3.2000e+01],\n",
       "                       [8.6451e-02, 9.5236e+00, 2.2691e+01, 3.0664e+01],\n",
       "                       [4.2429e-02, 6.8019e+00, 2.6584e+01, 2.8352e+01],\n",
       "                       [0.0000e+00, 1.7522e+01, 2.3330e+01, 3.1665e+01],\n",
       "                       [1.6465e+01, 0.0000e+00, 3.2000e+01, 1.5205e+01],\n",
       "                       [4.9215e+00, 1.1719e+01, 3.1959e+01, 3.1944e+01]]])),\n",
       "             ('sizes', tensor([[800, 800]])),\n",
       "             ('preds_per_image', tensor([36])),\n",
       "             ('roi_features',\n",
       "              tensor([[[0.0000e+00, 1.5776e-02, 1.9145e-01,  ..., 6.7119e-03,\n",
       "                        5.4843e-02, 1.2762e+00],\n",
       "                       [1.7170e-03, 3.0930e-01, 4.4900e-02,  ..., 1.6230e-02,\n",
       "                        7.5467e-01, 5.9343e-01],\n",
       "                       [2.9580e-02, 1.1725e-01, 2.7515e-01,  ..., 7.9398e-03,\n",
       "                        2.3030e-01, 1.7745e+00],\n",
       "                       ...,\n",
       "                       [0.0000e+00, 1.3097e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                        1.0691e+00, 7.0055e-02],\n",
       "                       [0.0000e+00, 6.3265e-01, 0.0000e+00,  ..., 3.5118e-01,\n",
       "                        4.0512e+00, 0.0000e+00],\n",
       "                       [0.0000e+00, 5.9211e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "                        2.3341e-01, 8.8419e-02]]])),\n",
       "             ('normalized_boxes',\n",
       "              tensor([[[2.3518e-01, 1.2253e-01, 4.4192e-01, 5.2080e-01],\n",
       "                       [1.9741e-01, 9.4934e-02, 4.9647e-01, 4.9240e-01],\n",
       "                       [2.5265e-01, 8.4465e-02, 4.5389e-01, 4.5408e-01],\n",
       "                       [1.4784e-01, 0.0000e+00, 8.2805e-01, 4.9687e-01],\n",
       "                       [2.1010e-01, 0.0000e+00, 9.2824e-01, 4.2284e-01],\n",
       "                       [4.9260e-01, 2.3144e-02, 7.1777e-01, 4.1453e-01],\n",
       "                       [4.4866e-01, 7.3397e-02, 6.9488e-01, 4.7777e-01],\n",
       "                       [2.7531e-01, 0.0000e+00, 8.9013e-01, 6.6383e-01],\n",
       "                       [5.1120e-01, 7.6206e-02, 7.4161e-01, 4.6195e-01],\n",
       "                       [2.5315e-01, 0.0000e+00, 7.5438e-01, 7.4557e-01],\n",
       "                       [1.3911e-01, 4.8307e-03, 6.7960e-01, 6.2074e-01],\n",
       "                       [4.4046e-01, 3.0476e-02, 7.5987e-01, 3.9705e-01],\n",
       "                       [1.7667e-01, 0.0000e+00, 9.9337e-01, 5.6216e-01],\n",
       "                       [1.6354e-02, 1.7607e-03, 7.9863e-01, 5.8760e-01],\n",
       "                       [3.6467e-01, 7.6208e-03, 7.7865e-01, 5.7891e-01],\n",
       "                       [1.2143e-01, 4.8290e-02, 8.0703e-01, 8.3553e-01],\n",
       "                       [2.9847e-01, 8.4378e-02, 9.5053e-01, 8.2742e-01],\n",
       "                       [3.8425e-01, 1.0647e-02, 8.2207e-01, 7.2509e-01],\n",
       "                       [4.2889e-01, 1.2124e-01, 7.7098e-01, 5.2975e-01],\n",
       "                       [4.2507e-01, 9.6579e-02, 9.9346e-01, 7.7158e-01],\n",
       "                       [1.2622e-02, 8.2768e-02, 7.2153e-01, 7.3750e-01],\n",
       "                       [4.1943e-01, 0.0000e+00, 9.9291e-01, 3.8071e-01],\n",
       "                       [3.7568e-01, 3.1445e-03, 8.9159e-01, 9.1390e-01],\n",
       "                       [0.0000e+00, 1.0168e-02, 4.5220e-01, 6.7402e-01],\n",
       "                       [0.0000e+00, 5.3425e-02, 4.2427e-01, 8.8593e-01],\n",
       "                       [6.1589e-03, 7.1928e-04, 9.9313e-01, 3.4643e-01],\n",
       "                       [7.2963e-03, 1.0153e-01, 5.1913e-01, 7.4007e-01],\n",
       "                       [8.1163e-02, 1.0340e-02, 5.7243e-01, 7.4450e-01],\n",
       "                       [1.2490e-02, 8.5090e-02, 5.7005e-01, 9.6761e-01],\n",
       "                       [3.6091e-01, 1.4670e-01, 8.2899e-01, 9.5606e-01],\n",
       "                       [2.4927e-03, 4.2259e-01, 8.8091e-01, 1.0000e+00],\n",
       "                       [2.7016e-03, 2.9761e-01, 7.0910e-01, 9.5824e-01],\n",
       "                       [1.3259e-03, 2.1256e-01, 8.3076e-01, 8.8599e-01],\n",
       "                       [0.0000e+00, 5.4755e-01, 7.2905e-01, 9.8953e-01],\n",
       "                       [5.1454e-01, 0.0000e+00, 9.9999e-01, 4.7516e-01],\n",
       "                       [1.5380e-01, 3.6623e-01, 9.9872e-01, 9.9824e-01]]]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, img_data in enumerate(train_data):\n",
    "    print(img_data)\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    # run frcnn\n",
    "    images, sizes, scales_yx = image_preprocess(image)\n",
    "    output_dict = frcnn(\n",
    "        images,\n",
    "        sizes,\n",
    "        scales_yx=scales_yx,\n",
    "        padding=\"max_detections\",\n",
    "        max_detections=frcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    \n",
    "#     visual_embeddings.append(features)\n",
    "#     labels.append(img_data[\"label\"])\n",
    "    break\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fbfed74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 36, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict['normalized_boxes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1cefb1e-2d87-4137-b44a-86089935763b",
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50000 embeddings\n",
      "On idx 0\n",
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n",
      "On idx 10000\n",
      "On idx 11000\n",
      "On idx 12000\n",
      "On idx 13000\n",
      "On idx 14000\n",
      "On idx 15000\n",
      "On idx 16000\n",
      "On idx 17000\n",
      "On idx 18000\n",
      "On idx 19000\n",
      "On idx 20000\n",
      "On idx 21000\n",
      "On idx 22000\n",
      "On idx 23000\n",
      "On idx 24000\n",
      "On idx 25000\n",
      "On idx 26000\n",
      "On idx 27000\n",
      "On idx 28000\n",
      "On idx 29000\n",
      "On idx 30000\n",
      "On idx 31000\n",
      "On idx 32000\n",
      "On idx 33000\n",
      "On idx 34000\n",
      "On idx 35000\n",
      "On idx 36000\n",
      "On idx 37000\n",
      "On idx 38000\n",
      "On idx 39000\n",
      "On idx 40000\n",
      "On idx 41000\n",
      "On idx 42000\n",
      "On idx 43000\n",
      "On idx 44000\n",
      "On idx 45000\n",
      "On idx 46000\n",
      "On idx 47000\n",
      "On idx 48000\n",
      "On idx 49000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(train_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "labels = []\n",
    "bounding_boxes = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(train_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    # run frcnn\n",
    "    images, sizes, scales_yx = image_preprocess(image)\n",
    "    output_dict = frcnn(\n",
    "        images,\n",
    "        sizes,\n",
    "        scales_yx=scales_yx,\n",
    "        padding=\"max_detections\",\n",
    "        max_detections=frcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    box = output_dict.get(\"normalized_boxes\")\n",
    "    \n",
    "    visual_embeddings.append(features)\n",
    "    bounding_boxes.append(box)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e6e6b20-0223-4776-ba26-2ca42da7a9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar10_train_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"bounding_box\": bounding_boxes,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-train-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar10_train_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64eed64b-6a16-460c-bf6b-a84f1ab7eb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 embeddings\n",
      "On idx 0\n",
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(test_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "labels = []\n",
    "bounding_boxes = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(test_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    # run frcnn\n",
    "    images, sizes, scales_yx = image_preprocess(image)\n",
    "    output_dict = frcnn(\n",
    "        images,\n",
    "        sizes,\n",
    "        scales_yx=scales_yx,\n",
    "        padding=\"max_detections\",\n",
    "        max_detections=frcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    box = output_dict.get(\"normalized_boxes\")\n",
    "    \n",
    "    visual_embeddings.append(features)\n",
    "    bounding_boxes.append(box)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77d322f0-0da5-46a6-9cec-f1c52cbdaf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar10_test_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"bounding_box\": bounding_boxes,\n",
    "    \"labels\": labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-test-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar10_test_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cb6dd-b6ec-43b7-a312-10cd13a0bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
