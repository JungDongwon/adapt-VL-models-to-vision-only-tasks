{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcf31be-2c72-4f3b-8e8e-4d4df20eec01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8981364-9818-44f9-adbc-97cbb8282445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_detectron2_model(config_file, model_weights, device):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.WEIGHTS = model_weights\n",
    "    cfg.MODEL.DEVICE = device\n",
    "\n",
    "    model = build_model(cfg)\n",
    "    model.eval()\n",
    "    DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5973abc-974e-4b1a-959f-64fc7c191ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar100 (/root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deb1ac61d83402aad82b3652fcbc81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar100_data = load_dataset(\"cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5b6644-b809-403c-9ce8-9077529028fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = cifar100_data[\"train\"]\n",
    "test_data = cifar100_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1665784-bc9c-4bbc-a651-858795b1c3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config_file = \"faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "model_weights = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
    "model = setup_detectron2_model(config_file, model_weights, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9653eeb-b0a3-4d75-9acb-ec7c7b517198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_roi_features(image, model):\n",
    "    image = to_tensor(image)  # Convert image to a PyTorch tensor\n",
    "    image = image.to(model.device)  # Move image to the same device as the model\n",
    "    image = (image * 255).to(torch.uint8)  # Convert back to the original range (0-255)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_image = model.preprocess_image([{\"image\": image, \"height\": image.shape[-2], \"width\": image.shape[-1]}])\n",
    "        features = model.backbone(input_image.tensor)\n",
    "        proposals, _ = model.proposal_generator(input_image, features)\n",
    "        box_features = model.roi_heads.box_pooler(\n",
    "            [features[f] for f in features if f!='p6'],\n",
    "            [p.proposal_boxes for p in proposals]\n",
    "        )\n",
    "        box_features = model.roi_heads.box_head(box_features) ## FINAL Features\n",
    "        \n",
    "    return box_features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1cefb1e-2d87-4137-b44a-86089935763b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50000 embeddings\n",
      "On idx 0\n",
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n",
      "On idx 10000\n",
      "On idx 11000\n",
      "On idx 12000\n",
      "On idx 13000\n",
      "On idx 14000\n",
      "On idx 15000\n",
      "On idx 16000\n",
      "On idx 17000\n",
      "On idx 18000\n",
      "On idx 19000\n",
      "On idx 20000\n",
      "On idx 21000\n",
      "On idx 22000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOn idx \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(idx))\n\u001b[1;32m     10\u001b[0m image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mextract_roi_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m visual_embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[1;32m     13\u001b[0m fine_labels\u001b[38;5;241m.\u001b[39mappend(img_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfine_label\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m, in \u001b[0;36mextract_roi_features\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     input_image \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpreprocess_image([{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: image, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m: image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m: image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]}])\n\u001b[0;32m----> 8\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     proposals, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mproposal_generator(input_image, features)\n\u001b[1;32m     10\u001b[0m     box_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mroi_heads\u001b[38;5;241m.\u001b[39mbox_pooler(\n\u001b[1;32m     11\u001b[0m         [features[f] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp6\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     12\u001b[0m         [p\u001b[38;5;241m.\u001b[39mproposal_boxes \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m proposals]\n\u001b[1;32m     13\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/modeling/backbone/fpn.py:139\u001b[0m, in \u001b[0;36mFPN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        input (dict[str->Tensor]): mapping feature map name (e.g., \"res5\") to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m            [\"p2\", \"p3\", ..., \"p6\"].\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     bottom_up_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbottom_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    141\u001b[0m     prev_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlateral_convs[\u001b[38;5;241m0\u001b[39m](bottom_up_features[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/modeling/backbone/resnet.py:449\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    447\u001b[0m     outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, stage \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage_names, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages):\n\u001b[0;32m--> 449\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_features:\n\u001b[1;32m    451\u001b[0m         outputs[name] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/modeling/backbone/resnet.py:198\u001b[0m, in \u001b[0;36mBottleneckBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    195\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m    196\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu_(out)\n\u001b[0;32m--> 198\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu_(out)\n\u001b[1;32m    201\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/detectron2/layers/wrappers.py:127\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    122\u001b[0m                 \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/12013\u001b[39;00m\n\u001b[1;32m    123\u001b[0m                 \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    124\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSyncBatchNorm\n\u001b[1;32m    125\u001b[0m                 ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyncBatchNorm does not support empty inputs!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 127\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(train_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(train_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    embedding = extract_roi_features(image, model)\n",
    "    visual_embeddings.append(embedding)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80125542-818d-4a31-b4ed-952a130994ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_train_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"fine_labels\": fine_labels,\n",
    "    \"coarse_labels\": coarse_labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-train-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar100_train_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64eed64b-6a16-460c-bf6b-a84f1ab7eb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 embeddings\n",
      "On idx 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(test_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(test_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    embedding = extract_roi_features(image, model)\n",
    "    visual_embeddings.append(embedding)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d322f0-0da5-46a6-9cec-f1c52cbdaf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_test_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"fine_labels\": fine_labels,\n",
    "    \"coarse_labels\": coarse_labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-test-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar100_test_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ecb12d-6fdb-46cd-876e-e9006320dba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar100_test_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcifar100_test_embeddings\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoarse_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cifar100_test_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "cifar100_test_embeddings['coarse_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cb6dd-b6ec-43b7-a312-10cd13a0bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
