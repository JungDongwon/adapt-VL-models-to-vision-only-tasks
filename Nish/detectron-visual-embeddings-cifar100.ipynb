{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebcf31be-2c72-4f3b-8e8e-4d4df20eec01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8981364-9818-44f9-adbc-97cbb8282445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_detectron2_model(config_file, model_weights, device):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.WEIGHTS = model_weights\n",
    "    cfg.MODEL.DEVICE = device\n",
    "\n",
    "    model = build_model(cfg)\n",
    "    model.eval()\n",
    "    DetectionCheckpointer(model).load(cfg.MODEL.WEIGHTS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5973abc-974e-4b1a-959f-64fc7c191ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e90f98762ac4a86abdcbd2342b78f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66267df1ddb4deba7bba21effad4361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c06caf4acc9463392c315c79e6dcfa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cifar100/cifar100 to /root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cc1b180c1241dd9e911bb00112df14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/169M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:319: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cifar100 downloaded and prepared to /root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e82fb31efc40e7863238e82ed62b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar100_data = load_dataset(\"cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5b6644-b809-403c-9ce8-9077529028fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = cifar100_data[\"train\"]\n",
    "test_data = cifar100_data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1665784-bc9c-4bbc-a651-858795b1c3ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "model_final_280758.pkl: 0.00B [00:00, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   0%|          | 8.19k/167M [00:00<5:15:17, 8.84kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   0%|          | 16.4k/167M [00:01<2:38:00, 17.6kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   0%|          | 57.3k/167M [00:01<37:56, 73.5kB/s]  \u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   0%|          | 147k/167M [00:01<13:49, 201kB/s]  \u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   0%|          | 319k/167M [00:01<06:10, 451kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   0%|          | 672k/167M [00:01<02:49, 983kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   1%|          | 1.36M/167M [00:01<01:21, 2.03MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   2%|▏         | 2.74M/167M [00:01<00:39, 4.20MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   3%|▎         | 5.51M/167M [00:02<00:18, 8.58MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   5%|▌         | 9.04M/167M [00:02<00:11, 13.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:   8%|▊         | 12.7M/167M [00:02<00:09, 17.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  10%|▉         | 16.5M/167M [00:02<00:07, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  12%|█▏        | 20.4M/167M [00:02<00:06, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  15%|█▍        | 24.4M/167M [00:02<00:06, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  16%|█▋        | 27.4M/167M [00:02<00:06, 23.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  19%|█▊        | 31.3M/167M [00:03<00:05, 24.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  21%|██        | 34.4M/167M [00:03<00:05, 23.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  23%|██▎       | 38.4M/167M [00:03<00:05, 24.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  25%|██▌       | 42.3M/167M [00:03<00:04, 25.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  28%|██▊       | 46.2M/167M [00:03<00:04, 26.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  30%|██▉       | 50.1M/167M [00:03<00:04, 26.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  32%|███▏      | 54.0M/167M [00:03<00:04, 26.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  35%|███▍      | 57.9M/167M [00:04<00:04, 26.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  37%|███▋      | 61.8M/167M [00:04<00:03, 27.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  39%|███▉      | 65.7M/167M [00:04<00:03, 27.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  42%|████▏     | 69.6M/167M [00:04<00:03, 27.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  44%|████▍     | 73.6M/167M [00:04<00:03, 27.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  46%|████▋     | 77.5M/167M [00:04<00:03, 27.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  49%|████▊     | 81.4M/167M [00:04<00:03, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  51%|█████     | 85.3M/167M [00:05<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  53%|█████▎    | 89.2M/167M [00:05<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  56%|█████▌    | 93.2M/167M [00:05<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  58%|█████▊    | 97.1M/167M [00:05<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  60%|██████    | 101M/167M [00:05<00:02, 27.4MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  63%|██████▎   | 105M/167M [00:05<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  65%|██████▌   | 109M/167M [00:05<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  67%|██████▋   | 113M/167M [00:06<00:01, 27.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  69%|██████▉   | 116M/167M [00:06<00:02, 25.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  71%|███████▏  | 119M/167M [00:06<00:01, 25.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  74%|███████▎  | 123M/167M [00:06<00:01, 26.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  76%|███████▌  | 127M/167M [00:06<00:01, 26.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  78%|███████▊  | 131M/167M [00:06<00:01, 26.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  81%|████████  | 135M/167M [00:06<00:01, 26.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  83%|████████▎ | 139M/167M [00:07<00:01, 26.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  85%|████████▌ | 143M/167M [00:07<00:00, 27.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  88%|████████▊ | 147M/167M [00:07<00:00, 27.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  90%|████████▉ | 151M/167M [00:07<00:00, 27.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  92%|█████████▏| 154M/167M [00:07<00:00, 27.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  95%|█████████▍| 158M/167M [00:07<00:00, 27.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl:  97%|█████████▋| 162M/167M [00:07<00:00, 27.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model_final_280758.pkl: 167MB [00:08, 20.7MB/s]                           \u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config_file = \"faster_rcnn_R_50_FPN_3x.yaml\"\n",
    "model_weights = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n",
    "model = setup_detectron2_model(config_file, model_weights, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9653eeb-b0a3-4d75-9acb-ec7c7b517198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_roi_features(image, model):\n",
    "    image = to_tensor(image)  # Convert image to a PyTorch tensor\n",
    "    image = image.to(model.device)  # Move image to the same device as the model\n",
    "    image = (image * 255).to(torch.uint8)  # Convert back to the original range (0-255)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_image = model.preprocess_image([{\"image\": image, \"height\": image.shape[-2], \"width\": image.shape[-1]}])\n",
    "        features = model.backbone(input_image.tensor)\n",
    "        proposals, _ = model.proposal_generator(input_image, features)\n",
    "        box_features = model.roi_heads.box_pooler(\n",
    "            [features[f] for f in features if f!='p6'],\n",
    "            [p.proposal_boxes for p in proposals]\n",
    "        )\n",
    "        box_features = model.roi_heads.box_head(box_features) ## FINAL Features\n",
    "        \n",
    "    return box_features.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1cefb1e-2d87-4137-b44a-86089935763b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50000 embeddings\n",
      "On idx 0\n",
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n",
      "On idx 10000\n",
      "On idx 11000\n",
      "On idx 12000\n",
      "On idx 13000\n",
      "On idx 14000\n",
      "On idx 15000\n",
      "On idx 16000\n",
      "On idx 17000\n",
      "On idx 18000\n",
      "On idx 19000\n",
      "On idx 20000\n",
      "On idx 21000\n",
      "On idx 22000\n",
      "On idx 23000\n",
      "On idx 24000\n",
      "On idx 25000\n",
      "On idx 26000\n",
      "On idx 27000\n",
      "On idx 28000\n",
      "On idx 29000\n",
      "On idx 30000\n",
      "On idx 31000\n",
      "On idx 32000\n",
      "On idx 33000\n",
      "On idx 34000\n",
      "On idx 35000\n",
      "On idx 36000\n",
      "On idx 37000\n",
      "On idx 38000\n",
      "On idx 39000\n",
      "On idx 40000\n",
      "On idx 41000\n",
      "On idx 42000\n",
      "On idx 43000\n",
      "On idx 44000\n",
      "On idx 45000\n",
      "On idx 46000\n",
      "On idx 47000\n",
      "On idx 48000\n",
      "On idx 49000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(train_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(train_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    embedding = extract_roi_features(image, model)\n",
    "    visual_embeddings.append(embedding)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0c0e04b-09b3-4484-839f-77955b75d76a",
   "metadata": {
    "tags": []
   },
   "source": [
    "lowest = 1000\n",
    "\n",
    "for e in visual_embeddings:\n",
    "    lowest = min(lowest, e.size(0))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7b30942-6630-4250-af90-fff7be419729",
   "metadata": {
    "tags": []
   },
   "source": [
    "lowest"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6b4a595-30bf-4242-b73e-feb4bec260ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "for idx, e in enumerate(visual_embeddings):\n",
    "    visual_embeddings[idx] = e[:lowest]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5152880-d6b8-45d4-8cf3-4ce69842584f",
   "metadata": {
    "tags": []
   },
   "source": [
    "for split in [10000, 20000, 30000, 40000, 50000]:\n",
    "    cifar100_train_embeddings = {\n",
    "        \"embeddings\": visual_embeddings[split-10000:split],\n",
    "        \"fine_labels\": fine_labels[split-10000:split],\n",
    "        \"coarse_labels\": coarse_labels[split-10000:split]\n",
    "    }\n",
    "\n",
    "    with open(\"cifar100-train-embeddings-\" + str(split) + \".pkl\", \"wb\") as f:\n",
    "        pickle.dump(cifar100_train_embeddings, f)\n",
    "    \n",
    "    print(\"Dumped \" + str(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6e6b20-0223-4776-ba26-2ca42da7a9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_train_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"fine_labels\": fine_labels,\n",
    "    \"coarse_labels\": coarse_labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-train-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar100_train_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64eed64b-6a16-460c-bf6b-a84f1ab7eb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 embeddings\n",
      "On idx 0\n",
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(test_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(test_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    embedding = extract_roi_features(image, model)\n",
    "    visual_embeddings.append(embedding)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d322f0-0da5-46a6-9cec-f1c52cbdaf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_test_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"fine_labels\": fine_labels,\n",
    "    \"coarse_labels\": coarse_labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-test-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar100_test_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cb6dd-b6ec-43b7-a312-10cd13a0bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
