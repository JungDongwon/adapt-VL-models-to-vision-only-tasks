{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af18e8ef-8d23-4a85-ad6c-088798ef2890",
   "metadata": {},
   "source": [
    "Trying to reimplement https://github.com/huggingface/transformers/blob/main/examples/research_projects/visual_bert/demo.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc38aaa-5077-44d2-a28e-22b79fee4473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import PIL.Image\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "from processing_image import Preprocess\n",
    "from visualizing_image import SingleImageViz\n",
    "from modeling_frcnn import GeneralizedRCNN\n",
    "from utils import Config\n",
    "import utils\n",
    "from transformers import VisualBertForQuestionAnswering, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3654d69-85a4-48ff-8225-00d27f5d48f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6980ceda-cd90-4408-8835-102c87293972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# URL = \"https://datasets-server.huggingface.co/assets/Maysee/tiny-imagenet/--/Maysee--tiny-imagenet/train/2/image/image.jpg\"\n",
    "# URL = \"https://datasets-server.huggingface.co/assets/cifar100/--/cifar100/train/0/img/image.jpg\"\n",
    "# URL = \"./input.jpg\"\n",
    "URL = \"https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/images/input.jpg\"\n",
    "# URL = \"https://vqa.cloudcv.org/media/test2014/COCO_test2014_000000262567.jpg\"\n",
    "OBJ_URL = \"https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/genome/1600-400-20/objects_vocab.txt\"\n",
    "ATTR_URL = \"https://raw.githubusercontent.com/airsplay/py-bottom-up-attention/master/demo/data/genome/1600-400-20/attributes_vocab.txt\"\n",
    "VQA_URL = \"https://dl.fbaipublicfiles.com/pythia/data/answers_vqa.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ea44c9-184a-47fb-9243-af2ff76a161b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for visualizing output\n",
    "def showarray(a, fmt=\"jpeg\"):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8d3cc3-1cb3-4e47-bc44-db0b4dabeb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load object, attribute, and answer labels\n",
    "\n",
    "objids = utils.get_data(OBJ_URL)\n",
    "attrids = utils.get_data(ATTR_URL)\n",
    "vqa_answers = utils.get_data(VQA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db576df-fb79-4f8e-8d82-502cf525eb6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n"
     ]
    }
   ],
   "source": [
    "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "image_preprocess = Preprocess(frcnn_cfg)\n",
    "images, sizes, scales_yx = image_preprocess(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1519279-758c-49b2-a0da-98f26c08975b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n",
      "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /root/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\n"
     ]
    }
   ],
   "source": [
    "# load models and model components\n",
    "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "\n",
    "frcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=frcnn_cfg)\n",
    "\n",
    "image_preprocess = Preprocess(frcnn_cfg)\n",
    "\n",
    "bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "visualbert_vqa = VisualBertForQuestionAnswering.from_pretrained(\"uclanlp/visualbert-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaae5ef7-5968-403f-ad8b-f20a3fdd6dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# image viz\n",
    "frcnn_visualizer = SingleImageViz(URL, id2obj=objids, id2attr=attrids)\n",
    "# run frcnn\n",
    "images, sizes, scales_yx = image_preprocess(URL)\n",
    "output_dict = frcnn(\n",
    "    images,\n",
    "    sizes,\n",
    "    scales_yx=scales_yx,\n",
    "    padding=\"max_detections\",\n",
    "    max_detections=frcnn_cfg.max_detections,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "# add boxes and labels to the image\n",
    "\n",
    "frcnn_visualizer.draw_boxes(\n",
    "    output_dict.get(\"boxes\"),\n",
    "    output_dict.pop(\"obj_ids\"),\n",
    "    output_dict.pop(\"obj_probs\"),\n",
    "    output_dict.pop(\"attr_ids\"),\n",
    "    output_dict.pop(\"attr_probs\"),\n",
    ")\n",
    "showarray(frcnn_visualizer._get_buffer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1801396b-d07a-42d0-a920-e1547cca54c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_questions_for_url1 = [\n",
    "#     \"Where is this scene?\",\n",
    "#     \"what is the man riding?\",\n",
    "#     \"What is the man wearing?\",\n",
    "#     \"What is the color of the horse?\"\n",
    "# ]\n",
    "\n",
    "test_questions_for_url1 = [\n",
    "    \"What color is the animal?\"\n",
    "]\n",
    "\n",
    "features = output_dict.get(\"roi_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30cf2969-a17a-4fe5-b3fd-88e6bd632c24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: ['What color is the animal?']\n",
      "prediction from VisualBert VQA: white\n"
     ]
    }
   ],
   "source": [
    "for test_question in test_questions_for_url1:\n",
    "    test_question = [test_question]\n",
    "\n",
    "    inputs = bert_tokenizer(\n",
    "        test_question,\n",
    "        padding=\"max_length\",\n",
    "        max_length=20,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    output_vqa = visualbert_vqa(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        visual_embeds=features,\n",
    "        visual_attention_mask=torch.ones(features.shape[:-1]),\n",
    "        token_type_ids=inputs.token_type_ids,\n",
    "        output_attentions=False,\n",
    "    )\n",
    "    # get prediction\n",
    "    pred_vqa = output_vqa[\"logits\"].argmax(-1)\n",
    "    print(\"Question:\", test_question)\n",
    "    print(\"prediction from VisualBert VQA:\", vqa_answers[pred_vqa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487c9a1-8681-4398-858b-3ea9dab3e157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
