{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcf31be-2c72-4f3b-8e8e-4d4df20eec01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import PIL.Image\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "from processing_image import Preprocess\n",
    "from visualizing_image import SingleImageViz\n",
    "from modeling_frcnn import GeneralizedRCNN\n",
    "from utils import Config\n",
    "import utils\n",
    "from transformers import VisualBertForQuestionAnswering, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f639b7-5fa5-4e11-9dde-e594c519a460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Image\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a96d43-0d18-4750-893b-7b51ded57ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561d4619-ad18-467f-8412-a020e7c69011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22185457-c800-4aaa-9283-77c6414e1bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file cache\n",
      "%s not found in cache or force_download set to True, downloading to %s https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin /root/.cache/torch/transformers/tmp64uzat92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6f7101d5294befa526da89c152a62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/262M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /root/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\n",
      "All model checkpoint weights were used when initializing GeneralizedRCNN.\n",
      "\n",
      "All the weights of GeneralizedRCNN were initialized from the model checkpoint at unc-nlp/frcnn-vg-finetuned.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GeneralizedRCNN for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa6b6fb9621414ab86acac9cf2b54b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa434b083e44f109388cdb6ece85b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d5498203e8425dad223ac34352d33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0978edf951994dfeba163befb9f15bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6903726a350c4f7899775f5edb5bb532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/153k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d92044ce27484cb1db3073001a0f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/455M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load models and model components\n",
    "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "frcnn_cfg.model.DEVICE = device\n",
    "\n",
    "frcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=frcnn_cfg).to(device)\n",
    "\n",
    "image_preprocess = Preprocess(frcnn_cfg)\n",
    "\n",
    "# bert_tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "# visualbert_vqa = VisualBertForQuestionAnswering.from_pretrained(\"uclanlp/visualbert-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5973abc-974e-4b1a-959f-64fc7c191ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431e594dd9ee44ad88f434afa83b670a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b1c9c8e3f84f2e908d1cb503563819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/4.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21df67e420ed4df4a5def8795399279d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/9.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset cifar100/cifar100 to /root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100729603a484451a43fcf47cfe18fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/169M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n",
      "  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cifar100 downloaded and prepared to /root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20611fa7175f45e89f2b904686c3396e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar100_data = load_dataset(\"cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5b6644-b809-403c-9ce8-9077529028fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = cifar100_data[\"train\"]\n",
    "test_data = cifar100_data[\"test\"]\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1cefb1e-2d87-4137-b44a-86089935763b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 50000 embeddings\n",
      "On idx 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n",
      "On idx 10000\n",
      "On idx 11000\n",
      "On idx 12000\n",
      "On idx 13000\n",
      "On idx 14000\n",
      "On idx 15000\n",
      "On idx 16000\n",
      "On idx 17000\n",
      "On idx 18000\n",
      "On idx 19000\n",
      "On idx 20000\n",
      "On idx 21000\n",
      "On idx 22000\n",
      "On idx 23000\n",
      "On idx 24000\n",
      "On idx 25000\n",
      "On idx 26000\n",
      "On idx 27000\n",
      "On idx 28000\n",
      "On idx 29000\n",
      "On idx 30000\n",
      "On idx 31000\n",
      "On idx 32000\n",
      "On idx 33000\n",
      "On idx 34000\n",
      "On idx 35000\n",
      "On idx 36000\n",
      "On idx 37000\n",
      "On idx 38000\n",
      "On idx 39000\n",
      "On idx 40000\n",
      "On idx 41000\n",
      "On idx 42000\n",
      "On idx 43000\n",
      "On idx 44000\n",
      "On idx 45000\n",
      "On idx 46000\n",
      "On idx 47000\n",
      "On idx 48000\n",
      "On idx 49000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(train_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(train_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    # run frcnn\n",
    "    images, sizes, scales_yx = image_preprocess(image)\n",
    "    output_dict = frcnn(\n",
    "        images,\n",
    "        sizes,\n",
    "        scales_yx=scales_yx,\n",
    "        padding=\"max_detections\",\n",
    "        max_detections=frcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    \n",
    "    visual_embeddings.append(features)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e6e6b20-0223-4776-ba26-2ca42da7a9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_train_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"fine_labels\": fine_labels,\n",
    "    \"coarse_labels\": coarse_labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-train-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar100_train_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64eed64b-6a16-460c-bf6b-a84f1ab7eb64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 10000 embeddings\n",
      "On idx 0\n",
      "On idx 1000\n",
      "On idx 2000\n",
      "On idx 3000\n",
      "On idx 4000\n",
      "On idx 5000\n",
      "On idx 6000\n",
      "On idx 7000\n",
      "On idx 8000\n",
      "On idx 9000\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating \" + str(len(test_data)) + \" embeddings\")\n",
    "\n",
    "visual_embeddings = []\n",
    "fine_labels = []\n",
    "coarse_labels = []\n",
    "\n",
    "for idx, img_data in enumerate(test_data):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"On idx \" + str(idx))\n",
    "    image = np.array(img_data[\"img\"])\n",
    "    # run frcnn\n",
    "    images, sizes, scales_yx = image_preprocess(image)\n",
    "    output_dict = frcnn(\n",
    "        images,\n",
    "        sizes,\n",
    "        scales_yx=scales_yx,\n",
    "        padding=\"max_detections\",\n",
    "        max_detections=frcnn_cfg.max_detections,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    features = output_dict.get(\"roi_features\")\n",
    "    \n",
    "    visual_embeddings.append(features)\n",
    "    fine_labels.append(img_data[\"fine_label\"])\n",
    "    coarse_labels.append(img_data[\"coarse_label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77d322f0-0da5-46a6-9cec-f1c52cbdaf4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cifar100_test_embeddings = {\n",
    "    \"embeddings\": visual_embeddings,\n",
    "    \"fine_labels\": fine_labels,\n",
    "    \"coarse_labels\": coarse_labels\n",
    "}\n",
    "\n",
    "with open(\"cifar100-test-embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cifar100_test_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7cb6dd-b6ec-43b7-a312-10cd13a0bbdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
