{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372955fe-ec44-4c9f-8a51-e8ce886a0c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, Image\n",
    "\n",
    "from transformers import BlipForQuestionAnswering, BlipProcessor, BlipConfig, BlipModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7920a9b0-75ee-423a-9b7b-ccdda33fb84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5356f74-5823-4e97-a9aa-0237bcef8b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, config, image_files, text, processor, num_labels):\n",
    "        self.config = config\n",
    "        self.image_files = image_files\n",
    "        self.text = text\n",
    "        self.processor = processor\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text\n",
    "        image = self.image_files[idx]['img']\n",
    "        label_id = self.image_files[idx]['fine_label']\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        # encoding = self.processor(image, text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        encoding = self.processor(image, text, return_tensors=\"pt\")\n",
    "        label_encoding = self.processor(text=self.config.id2label[str(label_id)], padding=\"max_length\", return_tensors=\"pt\").input_ids\n",
    "        label_encoding = label_encoding.squeeze()\n",
    "\n",
    "        # remove batch dimension\n",
    "        for k,v in encoding.items():\n",
    "            encoding[k] = v.squeeze()\n",
    "        #targets = torch.zeros(self.num_labels)\n",
    "        #targets[label_id] = 1\n",
    "        encoding[\"labels\"] = label_encoding\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f9fe6-fb4d-497e-89f9-868c971850c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar100 (/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP Experiments/./cache/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01611185073852539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360acf50ead0492499121ae7a90674d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('cifar100', cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59785229-aebb-414a-99e5-ecf75d4a3ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 17:25:44.081324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 17:25:44.770062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2023-04-25 17:25:44.770174: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:/opt/amazon/efa/lib64:/opt/amazon/openmpi/lib64:/usr/local/cuda/efa/lib:/usr/local/cuda/lib:/usr/local/cuda:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/targets/x86_64-linux/lib:/usr/local/lib:/usr/lib:/lib:\n",
      "2023-04-25 17:25:44.770180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple tensor([[ 101, 6207,  102]])\n",
      "aquarium_fish tensor([[  101, 18257,  1035,  3869,   102]])\n",
      "baby tensor([[ 101, 3336,  102]])\n",
      "bear tensor([[ 101, 4562,  102]])\n",
      "beaver tensor([[  101, 13570,   102]])\n",
      "bed tensor([[ 101, 2793,  102]])\n",
      "bee tensor([[  101, 10506,   102]])\n",
      "beetle tensor([[ 101, 7813,  102]])\n",
      "bicycle tensor([[  101, 10165,   102]])\n",
      "bottle tensor([[ 101, 5835,  102]])\n",
      "bowl tensor([[ 101, 4605,  102]])\n",
      "boy tensor([[ 101, 2879,  102]])\n",
      "bridge tensor([[ 101, 2958,  102]])\n",
      "bus tensor([[ 101, 3902,  102]])\n",
      "butterfly tensor([[ 101, 9112,  102]])\n",
      "camel tensor([[  101, 19130,   102]])\n",
      "can tensor([[ 101, 2064,  102]])\n",
      "castle tensor([[ 101, 3317,  102]])\n",
      "caterpillar tensor([[  101, 23488,  8197, 17305,   102]])\n",
      "cattle tensor([[ 101, 7125,  102]])\n",
      "chair tensor([[ 101, 3242,  102]])\n",
      "chimpanzee tensor([[  101,  9610,  8737,  2319, 23940,   102]])\n",
      "clock tensor([[ 101, 5119,  102]])\n",
      "cloud tensor([[ 101, 6112,  102]])\n",
      "cockroach tensor([[  101, 10338,  3217,  6776,   102]])\n",
      "couch tensor([[ 101, 6411,  102]])\n",
      "crocodile tensor([[  101, 21843,   102]])\n",
      "cup tensor([[ 101, 2452,  102]])\n",
      "dinosaur tensor([[  101, 15799,   102]])\n",
      "dolphin tensor([[  101, 17801,   102]])\n",
      "elephant tensor([[  101, 10777,   102]])\n",
      "flatfish tensor([[ 101, 4257, 7529,  102]])\n",
      "forest tensor([[ 101, 3224,  102]])\n",
      "fox tensor([[ 101, 4419,  102]])\n",
      "girl tensor([[ 101, 2611,  102]])\n",
      "hamster tensor([[  101, 10654,  6238,   102]])\n",
      "house tensor([[ 101, 2160,  102]])\n",
      "kangaroo tensor([[  101, 21652,   102]])\n",
      "keyboard tensor([[ 101, 9019,  102]])\n",
      "lamp tensor([[  101, 10437,   102]])\n",
      "lawn_mower tensor([[  101, 10168,  1035,  9587, 13777,   102]])\n",
      "leopard tensor([[  101, 16240,   102]])\n",
      "lion tensor([[ 101, 7006,  102]])\n",
      "lizard tensor([[  101, 15450,   102]])\n",
      "lobster tensor([[  101, 27940,   102]])\n",
      "man tensor([[ 101, 2158,  102]])\n",
      "maple_tree tensor([[  101, 11035,  1035,  3392,   102]])\n",
      "motorcycle tensor([[ 101, 9055,  102]])\n",
      "mountain tensor([[ 101, 3137,  102]])\n",
      "mouse tensor([[ 101, 8000,  102]])\n",
      "mushroom tensor([[  101, 18565,   102]])\n",
      "oak_tree tensor([[ 101, 6116, 1035, 3392,  102]])\n",
      "orange tensor([[ 101, 4589,  102]])\n",
      "orchid tensor([[  101, 15573,   102]])\n",
      "otter tensor([[  101, 22279,   102]])\n",
      "palm_tree tensor([[ 101, 5340, 1035, 3392,  102]])\n",
      "pear tensor([[  101, 28253,   102]])\n",
      "pickup_truck tensor([[  101, 15373,  1035,  4744,   102]])\n",
      "pine_tree tensor([[ 101, 7222, 1035, 3392,  102]])\n",
      "plain tensor([[ 101, 5810,  102]])\n",
      "plate tensor([[ 101, 5127,  102]])\n",
      "poppy tensor([[  101, 19745,   102]])\n",
      "porcupine tensor([[  101, 18499, 15569,  3170,   102]])\n",
      "possum tensor([[  101, 13433,  4757,  2819,   102]])\n",
      "rabbit tensor([[  101, 10442,   102]])\n",
      "raccoon tensor([[  101, 10958, 21408,  2239,   102]])\n",
      "ray tensor([[ 101, 4097,  102]])\n",
      "road tensor([[ 101, 2346,  102]])\n",
      "rocket tensor([[ 101, 7596,  102]])\n",
      "rose tensor([[ 101, 3123,  102]])\n",
      "sea tensor([[ 101, 2712,  102]])\n",
      "seal tensor([[ 101, 7744,  102]])\n",
      "shark tensor([[  101, 11420,   102]])\n",
      "shrew tensor([[  101, 14021, 15603,   102]])\n",
      "skunk tensor([[  101, 15315, 16814,   102]])\n",
      "skyscraper tensor([[  101, 24581,   102]])\n",
      "snail tensor([[  101, 10879,   102]])\n",
      "snake tensor([[ 101, 7488,  102]])\n",
      "spider tensor([[ 101, 6804,  102]])\n",
      "squirrel tensor([[  101, 18197,   102]])\n",
      "streetcar tensor([[  101, 21420,   102]])\n",
      "sunflower tensor([[  101,  3103, 14156,   102]])\n",
      "sweet_pepper tensor([[  101,  4086,  1035, 11565,   102]])\n",
      "table tensor([[ 101, 2795,  102]])\n",
      "tank tensor([[ 101, 4951,  102]])\n",
      "telephone tensor([[ 101, 7026,  102]])\n",
      "television tensor([[ 101, 2547,  102]])\n",
      "tiger tensor([[ 101, 6816,  102]])\n",
      "tractor tensor([[  101, 16358,   102]])\n",
      "train tensor([[ 101, 3345,  102]])\n",
      "trout tensor([[  101, 13452,   102]])\n",
      "tulip tensor([[  101, 10722, 15000,   102]])\n",
      "turtle tensor([[  101, 13170,   102]])\n",
      "wardrobe tensor([[  101, 17828,   102]])\n",
      "whale tensor([[  101, 13156,   102]])\n",
      "willow_tree tensor([[  101, 11940,  1035,  3392,   102]])\n",
      "wolf tensor([[ 101, 4702,  102]])\n",
      "woman tensor([[ 101, 2450,  102]])\n",
      "worm tensor([[  101, 15485,   102]])\n",
      "crab tensor([[  101, 18081,   102]])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "label_list = dataset[\"train\"].features[\"fine_label\"].names\n",
    "\n",
    "# replace label 'cra' to 'crab'\n",
    "label_list.remove('cra')\n",
    "label_list.append('crab')\n",
    "num_labels = len(label_list)\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "\n",
    "max_label_token_length = 0\n",
    "for label in label_list:\n",
    "    labels = processor(text=label, return_tensors=\"pt\").input_ids\n",
    "    max_label_token_length = max(max_label_token_length, len(labels[0]))\n",
    "    print(label, labels)\n",
    "print(max_label_token_length)\n",
    "\n",
    "config = BlipConfig.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "config.id2label = {str(i): label for i, label in enumerate(label_list)}\n",
    "config.label2id = {label: str(i) for i, label in enumerate(label_list)}\n",
    "config.num_labels = num_labels\n",
    "#config.max_length = max_label_token_length\n",
    "config.text_config.max_length = max_label_token_length # for CLS and SEP tokens\n",
    "\n",
    "\n",
    "train_dataset = ImageDataset(config, image_files=dataset[\"train\"], text=\"\", processor=processor, num_labels=num_labels)\n",
    "test_dataset = ImageDataset(config, image_files=dataset[\"test\"], text=\"\", processor=processor, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05efa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = ['beaver', 'dolphin', 'otter', 'seal', 'whale', 'aquarium fish', 'flatfish', 'ray', 'shark', 'trout', 'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', 'bottles', 'bowls', 'cans', 'cups', 'plates', 'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers', 'clock', 'computer keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', 'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', 'bear', 'leopard', 'lion', 'tiger', 'wolf', 'bridge', 'castle', 'house', 'road', 'skyscraper', 'cloud', 'forest', 'mountain', 'plain', 'sea', 'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', 'fox', 'porcupine', 'possum', 'raccoon', 'skunk', 'crab', 'lobster', 'snail', 'spider', 'worm', 'baby', 'boy', 'girl', 'man', 'woman', 'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', 'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', 'maple', 'oak', 'palm', 'pine', 'willow', 'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train', 'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor']\n",
    "real_labels = set()\n",
    "for label in dataset[\"train\"].features[\"fine_label\"].names:\n",
    "    real_labels.add(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c45e32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tulip', 'willow_tree', 'man', 'tiger', 'trout', 'road', 'shrew', 'beaver', 'skyscraper', 'otter', 'chimpanzee', 'possum', 'bridge', 'apple', 'baby', 'mountain', 'bottle', 'turtle', 'porcupine', 'lamp', 'sea', 'clock', 'bee', 'poppy', 'maple_tree', 'plate', 'leopard', 'squirrel', 'bed', 'fox', 'bus', 'couch', 'oak_tree', 'kangaroo', 'flatfish', 'train', 'cattle', 'elephant', 'tractor', 'crocodile', 'tank', 'beetle', 'aquarium_fish', 'house', 'skunk', 'lawn_mower', 'motorcycle', 'hamster', 'mushroom', 'television', 'plain', 'camel', 'pine_tree', 'raccoon', 'cloud', 'lion', 'seal', 'dolphin', 'orchid', 'cup', 'chair', 'sweet_pepper', 'orange', 'snake', 'woman', 'bowl', 'shark', 'boy', 'sunflower', 'bicycle', 'cockroach', 'palm_tree', 'lobster', 'worm', 'table', 'streetcar', 'pickup_truck', 'spider', 'bear', 'whale', 'telephone', 'rocket', 'castle', 'can', 'rose', 'lizard', 'ray', 'caterpillar', 'keyboard', 'forest', 'dinosaur', 'pear', 'rabbit', 'wardrobe', 'butterfly', 'mouse', 'snail', 'crab', 'girl', 'wolf'}\n"
     ]
    }
   ],
   "source": [
    "print(real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d075fe15-aab5-4f41-a245-98dc6015cc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\", config=config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce999c9-d7b9-4b7a-bbc1-d4b569a2be7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  input_ids = [item['input_ids'] for item in batch]\n",
    "  pixel_values = [item['pixel_values'] for item in batch]\n",
    "  attention_mask = [item['attention_mask'] for item in batch]\n",
    "  # token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "  labels = [item['labels'] for item in batch]\n",
    "\n",
    "  # create padded pixel values and corresponding pixel mask\n",
    "  # encoding = processor.feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "  # create new batch\n",
    "  batch = {}\n",
    "  batch['input_ids'] = torch.stack(input_ids)\n",
    "  batch['attention_mask'] = torch.stack(attention_mask)\n",
    "  # batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "  # batch['pixel_values'] = encoding['pixel_values']\n",
    "  # batch['pixel_mask'] = encoding['pixel_mask']\n",
    "  batch['pixel_values'] = torch.stack(pixel_values)\n",
    "  batch['labels'] = torch.stack(labels)\n",
    "  # batch['labels'] = torch.Tensor(labels).type(torch.LongTensor).unsqueeze(1)\n",
    "\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f70cfc7e-517f-4e5f-944d-547af369a38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a41a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_decoder.cls.predictions.bias\n",
      "text_decoder.cls.predictions.transform.dense.weight\n",
      "text_decoder.cls.predictions.transform.dense.bias\n",
      "text_decoder.cls.predictions.transform.LayerNorm.weight\n",
      "text_decoder.cls.predictions.transform.LayerNorm.bias\n",
      "text_decoder.cls.predictions.decoder.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'text_decoder.cls' in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33566460-d37b-4f63-ab84-a04e7055753a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_decoder.cls.predictions.bias\n",
      "text_decoder.cls.predictions.transform.dense.weight\n",
      "text_decoder.cls.predictions.transform.dense.bias\n",
      "text_decoder.cls.predictions.transform.LayerNorm.weight\n",
      "text_decoder.cls.predictions.transform.LayerNorm.bias\n",
      "text_decoder.cls.predictions.decoder.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if 'text_decoder.cls' in name:\n",
    "        print(name)\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e3f2a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4446838-c178-4f36-ab96-f4111a1360e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyboard keyboard\n",
      "spider spider\n",
      "poppy poppy\n",
      "chair chair\n",
      "camel camel\n",
      "telephone telephone\n",
      "dinosaur dinosaur\n",
      "crab crab\n",
      "bear bear\n",
      "dinosaur dinosaur\n",
      "chair chair\n",
      "woman woman\n",
      "poppy poppy\n",
      "telephone telephone\n",
      "43.75\n",
      "mapletree mapletree\n",
      "television television\n",
      "bowl bowl\n",
      "pickuptruck pickuptruck\n",
      "seal seal\n",
      "cloud cloud\n",
      "plate plate\n",
      "pear pear\n",
      "skyscraper skyscraper\n",
      "plate plate\n",
      "turtle turtle\n",
      "pickuptruck pickuptruck\n",
      "bus bus\n",
      "cattle cattle\n",
      "sweetpepper sweetpepper\n",
      "orchid orchid\n",
      "rabbit rabbit\n",
      "apple apple\n",
      "table table\n",
      "59.375\n",
      "can can\n",
      "lobster lobster\n",
      "can can\n",
      "seal seal\n",
      "tank tank\n",
      "clock clock\n",
      "skyscraper skyscraper\n",
      "mouse mouse\n",
      "snail snail\n",
      "kangaroo kangaroo\n",
      "oaktree oaktree\n",
      "pinetree pinetree\n",
      "trout trout\n",
      "cloud cloud\n",
      "43.75\n",
      "leopard leopard\n",
      "baby baby\n",
      "apple apple\n",
      "clock clock\n",
      "whale whale\n",
      "mapletree mapletree\n",
      "bowl bowl\n",
      "woman woman\n",
      "rabbit rabbit\n",
      "wardrobe wardrobe\n",
      "31.25\n",
      "castle castle\n",
      "turtle turtle\n",
      "pear pear\n",
      "train train\n",
      "sea sea\n",
      "pickuptruck pickuptruck\n",
      "table table\n",
      "crab crab\n",
      "sweetpepper sweetpepper\n",
      "tank tank\n",
      "clock clock\n",
      "bicycle bicycle\n",
      "couch couch\n",
      "tank tank\n",
      "poppy poppy\n",
      "telephone telephone\n",
      "50.0\n",
      "girl girl\n",
      "bed bed\n",
      "bus bus\n",
      "rose rose\n",
      "mountain mountain\n",
      "trout trout\n",
      "boy boy\n",
      "plate plate\n",
      "turtle turtle\n",
      "bus bus\n",
      "kangaroo kangaroo\n",
      "34.375\n",
      "table table\n",
      "rocket rocket\n",
      "pear pear\n",
      "apple apple\n",
      "television television\n",
      "seal seal\n",
      "motorcycle motorcycle\n",
      "chair chair\n",
      "tank tank\n",
      "crab crab\n",
      "couch couch\n",
      "tractor tractor\n",
      "bus bus\n",
      "orchid orchid\n",
      "worm worm\n",
      "mapletree mapletree\n",
      "sweetpepper sweetpepper\n",
      "sea sea\n",
      "orchid orchid\n",
      "59.375\n",
      "kangaroo kangaroo\n",
      "apple apple\n",
      "skyscraper skyscraper\n",
      "lion lion\n",
      "turtle turtle\n",
      "train train\n",
      "pickuptruck pickuptruck\n",
      "snail snail\n",
      "motorcycle motorcycle\n",
      "bicycle bicycle\n",
      "table table\n",
      "kangaroo kangaroo\n",
      "couch couch\n",
      "television television\n",
      "43.75\n",
      "seal seal\n",
      "telephone telephone\n",
      "bridge bridge\n",
      "whale whale\n",
      "plate plate\n",
      "bed bed\n",
      "kangaroo kangaroo\n",
      "lawnmower lawnmower\n",
      "apple apple\n",
      "rocket rocket\n",
      "television television\n",
      "lamp lamp\n",
      "lawnmower lawnmower\n",
      "trout trout\n",
      "spider spider\n",
      "bed bed\n",
      "50.0\n",
      "worm worm\n",
      "tiger tiger\n",
      "can can\n",
      "bicycle bicycle\n",
      "spider spider\n",
      "spider spider\n",
      "seal seal\n",
      "clock clock\n",
      "turtle turtle\n",
      "streetcar streetcar\n",
      "bus bus\n",
      "cattle cattle\n",
      "mouse mouse\n",
      "lobster lobster\n",
      "dinosaur dinosaur\n",
      "bowl bowl\n",
      "oaktree oaktree\n",
      "train train\n",
      "56.25\n",
      "leopard leopard\n",
      "chair chair\n",
      "woman woman\n",
      "bicycle bicycle\n",
      "butterfly butterfly\n",
      "bicycle bicycle\n",
      "chair chair\n",
      "can can\n",
      "pear pear\n",
      "pinetree pinetree\n",
      "telephone telephone\n",
      "can can\n",
      "kangaroo kangaroo\n",
      "snail snail\n",
      "mapletree mapletree\n",
      "spider spider\n",
      "50.0\n",
      "girl girl\n",
      "leopard leopard\n",
      "bottle bottle\n",
      "bottle bottle\n",
      "camel camel\n",
      "beetle beetle\n",
      "butterfly butterfly\n",
      "seal seal\n",
      "motorcycle motorcycle\n",
      "palmtree palmtree\n",
      "willowtree willowtree\n",
      "orchid orchid\n",
      "skyscraper skyscraper\n",
      "40.625\n",
      "television television\n",
      "wolf wolf\n",
      "television television\n",
      "butterfly butterfly\n",
      "train train\n",
      "bridge bridge\n",
      "table table\n",
      "whale whale\n",
      "wolf wolf\n",
      "couch couch\n",
      "tractor tractor\n",
      "lamp lamp\n",
      "tiger tiger\n",
      "pickuptruck pickuptruck\n",
      "cloud cloud\n",
      "46.875\n",
      "chair chair\n",
      "cattle cattle\n",
      "chair chair\n",
      "snail snail\n",
      "bottle bottle\n",
      "pear pear\n",
      "cloud cloud\n",
      "crab crab\n",
      "butterfly butterfly\n",
      "can can\n",
      "telephone telephone\n",
      "rose rose\n",
      "mouse mouse\n",
      "willowtree willowtree\n",
      "tiger tiger\n",
      "dinosaur dinosaur\n",
      "plate plate\n",
      "palmtree palmtree\n",
      "56.25\n",
      "elephant elephant\n",
      "rose rose\n",
      "whale whale\n",
      "television television\n",
      "mapletree mapletree\n",
      "dinosaur dinosaur\n",
      "trout trout\n",
      "plate plate\n",
      "bridge bridge\n",
      "snail snail\n",
      "couch couch\n",
      "can can\n",
      "37.5\n",
      "lawnmower lawnmower\n",
      "tiger tiger\n",
      "chair chair\n",
      "cloud cloud\n",
      "apple apple\n",
      "turtle turtle\n",
      "lawnmower lawnmower\n",
      "seal seal\n",
      "plate plate\n",
      "leopard leopard\n",
      "camel camel\n",
      "crab crab\n",
      "butterfly butterfly\n",
      "plate plate\n",
      "43.75\n",
      "woman woman\n",
      "bus bus\n",
      "tank tank\n",
      "pinetree pinetree\n",
      "bridge bridge\n",
      "elephant elephant\n",
      "spider spider\n",
      "apple apple\n",
      "spider spider\n",
      "bowl bowl\n",
      "bus bus\n",
      "pear pear\n",
      "pickuptruck pickuptruck\n",
      "apple apple\n",
      "turtle turtle\n",
      "boy boy\n",
      "50.0\n",
      "pickuptruck pickuptruck\n",
      "bridge bridge\n",
      "rose rose\n",
      "castle castle\n",
      "snail snail\n",
      "mapletree mapletree\n",
      "tiger tiger\n",
      "orchid orchid\n",
      "leopard leopard\n",
      "mouse mouse\n",
      "table table\n",
      "spider spider\n",
      "cloud cloud\n",
      "train train\n",
      "43.75\n",
      "tulip tulip\n",
      "bottle bottle\n",
      "woman woman\n",
      "bridge bridge\n",
      "beetle beetle\n",
      "plate plate\n",
      "tank tank\n",
      "castle castle\n",
      "spider spider\n",
      "kangaroo kangaroo\n",
      "girl girl\n",
      "chair chair\n",
      "television television\n",
      "40.625\n",
      "rocket rocket\n",
      "couch couch\n",
      "telephone telephone\n",
      "apple apple\n",
      "snail snail\n",
      "mapletree mapletree\n",
      "dolphin dolphin\n",
      "boy boy\n",
      "television television\n",
      "kangaroo kangaroo\n",
      "seal seal\n",
      "34.375\n",
      "chair chair\n",
      "table table\n",
      "television television\n",
      "wolf wolf\n",
      "whale whale\n",
      "castle castle\n",
      "chair chair\n",
      "girl girl\n",
      "mapletree mapletree\n",
      "leopard leopard\n",
      "tank tank\n",
      "bee bee\n",
      "37.5\n",
      "snail snail\n",
      "apple apple\n",
      "apple apple\n",
      "can can\n",
      "clock clock\n",
      "dolphin dolphin\n",
      "mountain mountain\n",
      "wolf wolf\n",
      "cloud cloud\n",
      "apple apple\n",
      "plate plate\n",
      "turtle turtle\n",
      "mouse mouse\n",
      "clock clock\n",
      "43.75\n",
      "bus bus\n",
      "bed bed\n",
      "skyscraper skyscraper\n",
      "whale whale\n",
      "apple apple\n",
      "tractor tractor\n",
      "butterfly butterfly\n",
      "trout trout\n",
      "bus bus\n",
      "kangaroo kangaroo\n",
      "lobster lobster\n",
      "turtle turtle\n",
      "37.5\n",
      "snail snail\n",
      "poppy poppy\n",
      "leopard leopard\n",
      "plate plate\n",
      "bus bus\n",
      "bicycle bicycle\n",
      "cup cup\n",
      "lamp lamp\n",
      "bowl bowl\n",
      "rose rose\n",
      "pinetree pinetree\n",
      "castle castle\n",
      "boy boy\n",
      "table table\n",
      "bridge bridge\n",
      "clock clock\n",
      "baby baby\n",
      "mountain mountain\n",
      "56.25\n",
      "skyscraper skyscraper\n",
      "tank tank\n",
      "lawnmower lawnmower\n",
      "bowl bowl\n",
      "crab crab\n",
      "table table\n",
      "leopard leopard\n",
      "bottle bottle\n",
      "pear pear\n",
      "turtle turtle\n",
      "snake snake\n",
      "34.375\n",
      "skyscraper skyscraper\n",
      "bottle bottle\n",
      "cattle cattle\n",
      "kangaroo kangaroo\n",
      "woman woman\n",
      "whale whale\n",
      "leopard leopard\n",
      "trout trout\n",
      "dinosaur dinosaur\n",
      "squirrel squirrel\n",
      "table table\n",
      "table table\n",
      "chair chair\n",
      "40.625\n",
      "bed bed\n",
      "mouse mouse\n",
      "lobster lobster\n",
      "mapletree mapletree\n",
      "trout trout\n",
      "pear pear\n",
      "dolphin dolphin\n",
      "streetcar streetcar\n",
      "orchid orchid\n",
      "sweetpepper sweetpepper\n",
      "pear pear\n",
      "whale whale\n",
      "rose rose\n",
      "lamp lamp\n",
      "cattle cattle\n",
      "spider spider\n",
      "girl girl\n",
      "53.125\n",
      "rose rose\n",
      "lobster lobster\n",
      "girl girl\n",
      "skyscraper skyscraper\n",
      "tractor tractor\n",
      "lion lion\n",
      "cattle cattle\n",
      "willowtree willowtree\n",
      "skyscraper skyscraper\n",
      "couch couch\n",
      "girl girl\n",
      "snail snail\n",
      "plate plate\n",
      "telephone telephone\n",
      "clock clock\n",
      "lawnmower lawnmower\n",
      "crab crab\n",
      "tank tank\n",
      "56.25\n",
      "oaktree oaktree\n",
      "cattle cattle\n",
      "beetle beetle\n",
      "orchid orchid\n",
      "chair chair\n",
      "lobster lobster\n",
      "bee bee\n",
      "couch couch\n",
      "bee bee\n",
      "pickuptruck pickuptruck\n",
      "plate plate\n",
      "wardrobe wardrobe\n",
      "37.5\n",
      "castle castle\n",
      "snail snail\n",
      "trout trout\n",
      "seal seal\n",
      "train train\n",
      "chair chair\n",
      "kangaroo kangaroo\n",
      "television television\n",
      "bottle bottle\n",
      "rose rose\n",
      "butterfly butterfly\n",
      "clock clock\n",
      "turtle turtle\n",
      "dinosaur dinosaur\n",
      "bowl bowl\n",
      "bed bed\n",
      "lawnmower lawnmower\n",
      "cloud cloud\n",
      "56.25\n",
      "sweetpepper sweetpepper\n",
      "snail snail\n",
      "castle castle\n",
      "snail snail\n",
      "man man\n",
      "television television\n",
      "mapletree mapletree\n",
      "pinetree pinetree\n",
      "girl girl\n",
      "bridge bridge\n",
      "rabbit rabbit\n",
      "girl girl\n",
      "mapletree mapletree\n",
      "whale whale\n",
      "rabbit rabbit\n",
      "rocket rocket\n",
      "seal seal\n",
      "53.125\n",
      "telephone telephone\n",
      "wolf wolf\n",
      "castle castle\n",
      "dolphin dolphin\n",
      "train train\n",
      "bicycle bicycle\n",
      "plate plate\n",
      "worm worm\n",
      "seal seal\n",
      "oaktree oaktree\n",
      "mouse mouse\n",
      "butterfly butterfly\n",
      "trout trout\n",
      "mountain mountain\n",
      "rocket rocket\n",
      "leopard leopard\n",
      "50.0\n",
      "dinosaur dinosaur\n",
      "bus bus\n",
      "willowtree willowtree\n",
      "camel camel\n",
      "whale whale\n",
      "willowtree willowtree\n",
      "telephone telephone\n",
      "leopard leopard\n",
      "tiger tiger\n",
      "cloud cloud\n",
      "couch couch\n",
      "couch couch\n",
      "pear pear\n",
      "lion lion\n",
      "mushroom mushroom\n",
      "46.875\n",
      "lion lion\n",
      "sweetpepper sweetpepper\n",
      "lawnmower lawnmower\n",
      "turtle turtle\n",
      "willowtree willowtree\n",
      "wolf wolf\n",
      "leopard leopard\n",
      "bed bed\n",
      "poppy poppy\n",
      "mouse mouse\n",
      "chair chair\n",
      "lamp lamp\n",
      "tiger tiger\n",
      "40.625\n",
      "can can\n",
      "whale whale\n",
      "rocket rocket\n",
      "skyscraper skyscraper\n",
      "skyscraper skyscraper\n",
      "streetcar streetcar\n",
      "mapletree mapletree\n",
      "leopard leopard\n",
      "motorcycle motorcycle\n",
      "orchid orchid\n",
      "telephone telephone\n",
      "lobster lobster\n",
      "37.5\n",
      "lamp lamp\n",
      "bear bear\n",
      "trout trout\n",
      "sweetpepper sweetpepper\n",
      "mountain mountain\n",
      "baby baby\n",
      "rocket rocket\n",
      "rocket rocket\n",
      "chair chair\n",
      "trout trout\n",
      "woman woman\n",
      "lawnmower lawnmower\n",
      "37.5\n",
      "bed bed\n",
      "willowtree willowtree\n",
      "mapletree mapletree\n",
      "pinetree pinetree\n",
      "castle castle\n",
      "cloud cloud\n",
      "plate plate\n",
      "apple apple\n",
      "whale whale\n",
      "whale whale\n",
      "butterfly butterfly\n",
      "34.375\n",
      "palmtree palmtree\n",
      "seal seal\n",
      "leopard leopard\n",
      "orchid orchid\n",
      "camel camel\n",
      "train train\n",
      "rose rose\n",
      "butterfly butterfly\n",
      "train train\n",
      "sea sea\n",
      "telephone telephone\n",
      "camel camel\n",
      "castle castle\n",
      "pickuptruck pickuptruck\n",
      "skyscraper skyscraper\n",
      "snail snail\n",
      "clock clock\n",
      "sweetpepper sweetpepper\n",
      "56.25\n",
      "turtle turtle\n",
      "dolphin dolphin\n",
      "leopard leopard\n",
      "pinetree pinetree\n",
      "bed bed\n",
      "plate plate\n",
      "butterfly butterfly\n",
      "wolf wolf\n",
      "leopard leopard\n",
      "oaktree oaktree\n",
      "dinosaur dinosaur\n",
      "34.375\n",
      "palmtree palmtree\n",
      "bee bee\n",
      "bottle bottle\n",
      "snail snail\n",
      "streetcar streetcar\n",
      "mouse mouse\n",
      "chair chair\n",
      "orchid orchid\n",
      "mountain mountain\n",
      "28.125\n",
      "bowl bowl\n",
      "snail snail\n",
      "leopard leopard\n",
      "crab crab\n",
      "bed bed\n",
      "baby baby\n",
      "mouse mouse\n",
      "camel camel\n",
      "pickuptruck pickuptruck\n",
      "baby baby\n",
      "willowtree willowtree\n",
      "rose rose\n",
      "trout trout\n",
      "rabbit rabbit\n",
      "castle castle\n",
      "46.875\n",
      "chair chair\n",
      "mouse mouse\n",
      "kangaroo kangaroo\n",
      "bowl bowl\n",
      "table table\n",
      "telephone telephone\n",
      "wolf wolf\n",
      "snail snail\n",
      "seal seal\n",
      "bed bed\n",
      "dinosaur dinosaur\n",
      "bridge bridge\n",
      "tank tank\n",
      "telephone telephone\n",
      "43.75\n",
      "worm worm\n",
      "table table\n",
      "bowl bowl\n",
      "wolf wolf\n",
      "crab crab\n",
      "orchid orchid\n",
      "girl girl\n",
      "cattle cattle\n",
      "butterfly butterfly\n",
      "skyscraper skyscraper\n",
      "tractor tractor\n",
      "whale whale\n",
      "castle castle\n",
      "can can\n",
      "dinosaur dinosaur\n",
      "bee bee\n",
      "50.0\n",
      "telephone telephone\n",
      "worm worm\n",
      "telephone telephone\n",
      "lamp lamp\n",
      "bed bed\n",
      "lawnmower lawnmower\n",
      "pickuptruck pickuptruck\n",
      "bridge bridge\n",
      "motorcycle motorcycle\n",
      "bus bus\n",
      "sea sea\n",
      "tank tank\n",
      "apple apple\n",
      "mountain mountain\n",
      "clock clock\n",
      "46.875\n",
      "bus bus\n",
      "clock clock\n",
      "whale whale\n",
      "trout trout\n",
      "ray ray\n",
      "mapletree mapletree\n",
      "lion lion\n",
      "train train\n",
      "orchid orchid\n",
      "cattle cattle\n",
      "pinetree pinetree\n",
      "camel camel\n",
      "cattle cattle\n",
      "dinosaur dinosaur\n",
      "43.75\n",
      "spider spider\n",
      "chair chair\n",
      "train train\n",
      "elephant elephant\n",
      "couch couch\n",
      "butterfly butterfly\n",
      "cattle cattle\n",
      "worm worm\n",
      "tiger tiger\n",
      "whale whale\n",
      "whale whale\n",
      "lawnmower lawnmower\n",
      "squirrel squirrel\n",
      "trout trout\n",
      "43.75\n",
      "table table\n",
      "clock clock\n",
      "bowl bowl\n",
      "mouse mouse\n",
      "camel camel\n",
      "television television\n",
      "lobster lobster\n",
      "bridge bridge\n",
      "orchid orchid\n",
      "television television\n",
      "plate plate\n",
      "pinetree pinetree\n",
      "bed bed\n",
      "skyscraper skyscraper\n",
      "dinosaur dinosaur\n",
      "wolf wolf\n",
      "50.0\n",
      "table table\n",
      "orchid orchid\n",
      "telephone telephone\n",
      "couch couch\n",
      "rocket rocket\n",
      "snail snail\n",
      "orchid orchid\n",
      "woman woman\n",
      "sweetpepper sweetpepper\n",
      "telephone telephone\n",
      "clock clock\n",
      "oaktree oaktree\n",
      "chair chair\n",
      "dinosaur dinosaur\n",
      "43.75\n",
      "beetle beetle\n",
      "spider spider\n",
      "spider spider\n",
      "woman woman\n",
      "clock clock\n",
      "telephone telephone\n",
      "poppy poppy\n",
      "girl girl\n",
      "couch couch\n",
      "apple apple\n",
      "bottle bottle\n",
      "cattle cattle\n",
      "willowtree willowtree\n",
      "camel camel\n",
      "pinetree pinetree\n",
      "crab crab\n",
      "50.0\n",
      "pickuptruck pickuptruck\n",
      "mouse mouse\n",
      "turtle turtle\n",
      "seal seal\n",
      "sweetpepper sweetpepper\n",
      "mouse mouse\n",
      "pear pear\n",
      "wolf wolf\n",
      "boy boy\n",
      "bus bus\n",
      "trout trout\n",
      "poppy poppy\n",
      "bus bus\n",
      "40.625\n",
      "train train\n",
      "lion lion\n",
      "woman woman\n",
      "television television\n",
      "snail snail\n",
      "mouse mouse\n",
      "leopard leopard\n",
      "mapletree mapletree\n",
      "girl girl\n",
      "girl girl\n",
      "television television\n",
      "girl girl\n",
      "bed bed\n",
      "lamp lamp\n",
      "apple apple\n",
      "46.875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP Experiments/BLIP.ipynb Cell 14\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m total_acc \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m         batch \u001b[39m=\u001b[39m {k:v\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m         outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mgenerate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbatch)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP Experiments/BLIP.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_files[idx][\u001b[39m'\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     label_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_files[idx][\u001b[39m'\u001b[39m\u001b[39mfine_label\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B52.10.195.51/home/dongwon/adapt-VL-models-to-vision-only-tasks/Nish/BLIP%20Experiments/BLIP.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39mmode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/arrow_dataset.py:2658\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2657\u001b[0m     \u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2658\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/arrow_dataset.py:2643\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2641\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2642\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, key, indices\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 2643\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2644\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39;49mformatter, format_columns\u001b[39m=\u001b[39;49mformat_columns, output_all_columns\u001b[39m=\u001b[39;49moutput_all_columns\n\u001b[1;32m   2645\u001b[0m )\n\u001b[1;32m   2646\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/formatting/formatting.py:634\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    632\u001b[0m python_formatter \u001b[39m=\u001b[39m PythonFormatter(features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m format_columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     \u001b[39mreturn\u001b[39;00m formatter(pa_table, query_type\u001b[39m=\u001b[39;49mquery_type)\n\u001b[1;32m    635\u001b[0m \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    636\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m format_columns:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/formatting/formatting.py:406\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pa_table: pa\u001b[39m.\u001b[39mTable, query_type: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    405\u001b[0m     \u001b[39mif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_row(pa_table)\n\u001b[1;32m    407\u001b[0m     \u001b[39melif\u001b[39;00m query_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    408\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/formatting/formatting.py:442\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m LazyRow(pa_table, \u001b[39mself\u001b[39m)\n\u001b[1;32m    441\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_arrow_extractor()\u001b[39m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m--> 442\u001b[0m row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpython_features_decoder\u001b[39m.\u001b[39;49mdecode_row(row)\n\u001b[1;32m    443\u001b[0m \u001b[39mreturn\u001b[39;00m row\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/formatting/formatting.py:225\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_row\u001b[39m(\u001b[39mself\u001b[39m, row: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures\u001b[39m.\u001b[39;49mdecode_example(row) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures \u001b[39melse\u001b[39;00m row\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/features/features.py:1844\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[0;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1830\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_example\u001b[39m(\u001b[39mself\u001b[39m, example: \u001b[39mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[39mstr\u001b[39m, Union[\u001b[39mstr\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mNone\u001b[39;00m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1831\u001b[0m     \u001b[39m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   1832\u001b[0m \n\u001b[1;32m   1833\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[39m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m   1845\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[39m=\u001b[39mtoken_per_repo_id)\n\u001b[1;32m   1846\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   1847\u001b[0m         \u001b[39melse\u001b[39;00m value\n\u001b[1;32m   1848\u001b[0m         \u001b[39mfor\u001b[39;00m column_name, (feature, value) \u001b[39min\u001b[39;00m zip_dict(\n\u001b[1;32m   1849\u001b[0m             {key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m example}, example\n\u001b[1;32m   1850\u001b[0m         )\n\u001b[1;32m   1851\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/features/features.py:1845\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1830\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode_example\u001b[39m(\u001b[39mself\u001b[39m, example: \u001b[39mdict\u001b[39m, token_per_repo_id: Optional[Dict[\u001b[39mstr\u001b[39m, Union[\u001b[39mstr\u001b[39m, \u001b[39mbool\u001b[39m, \u001b[39mNone\u001b[39;00m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1831\u001b[0m     \u001b[39m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   1832\u001b[0m \n\u001b[1;32m   1833\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[39m        `dict[str, Any]`\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1844\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m-> 1845\u001b[0m         column_name: decode_nested_example(feature, value, token_per_repo_id\u001b[39m=\u001b[39;49mtoken_per_repo_id)\n\u001b[1;32m   1846\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   1847\u001b[0m         \u001b[39melse\u001b[39;00m value\n\u001b[1;32m   1848\u001b[0m         \u001b[39mfor\u001b[39;00m column_name, (feature, value) \u001b[39min\u001b[39;00m zip_dict(\n\u001b[1;32m   1849\u001b[0m             {key: value \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;00m example}, example\n\u001b[1;32m   1850\u001b[0m         )\n\u001b[1;32m   1851\u001b[0m     }\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/features/features.py:1308\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1305\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[1;32m   1306\u001b[0m     \u001b[39m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1307\u001b[0m     \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m schema\u001b[39m.\u001b[39mdecode:\n\u001b[0;32m-> 1308\u001b[0m         \u001b[39mreturn\u001b[39;00m schema\u001b[39m.\u001b[39;49mdecode_example(obj, token_per_repo_id\u001b[39m=\u001b[39;49mtoken_per_repo_id)\n\u001b[1;32m   1309\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/datasets/features/image.py:176\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     image \u001b[39m=\u001b[39m PIL\u001b[39m.\u001b[39mImage\u001b[39m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[0;32m--> 176\u001b[0m image\u001b[39m.\u001b[39;49mload()  \u001b[39m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/PIL/ImageFile.py:253\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n\u001b[1;32m    252\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 253\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    255\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=6e-4)\n",
    "num_epochs = 30\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.25)\n",
    "\n",
    "best_params = None\n",
    "best_val_accuracy = -1\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    step = 0\n",
    "    \"\"\"\n",
    "    for batch in tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        outputs = model(**batch) \n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss\n",
    "        step += 1\n",
    "            \n",
    "    scheduler.step()\n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels_eval = []\n",
    "    total_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k:v.to(device) for k,v in batch.items()}\n",
    "            \n",
    "            outputs = model.generate(**batch)\n",
    "            outputs = outputs[:,0:max_label_token_length]\n",
    "            #print('outputs:',processor.decode(outputs[0], skip_special_tokens=True), outputs[0])\n",
    "            labels = batch['labels'][:,0:max_label_token_length]\n",
    "            #print('labels:',processor.decode(labels[0], skip_special_tokens=True), labels[0])\n",
    "            outputs = processor.batch_decode(outputs, skip_special_tokens=True)\n",
    "            labels = processor.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "            # count how many are correct\n",
    "            correct = 0\n",
    "            for i in range(len(labels)):\n",
    "                output = outputs[i]\n",
    "                label = labels[i]\n",
    "                output = output.replace(\" \", \"\")\n",
    "                label = label.replace(\" \", \"\")\n",
    "                output = output.replace(\"_\", \"\")\n",
    "                label = label.replace(\"_\", \"\")\n",
    "                if output[:len(label)] == label:\n",
    "                    print(output[:len(label)], label)\n",
    "                    correct += 1\n",
    "            acc = (correct * 100) / len(labels)\n",
    "            print(acc)\n",
    "\n",
    "            total_acc += acc\n",
    "        print('total acc:',total_acc / len(val_dataloader))\n",
    "            \n",
    "            #val_predictions.extend(preds.cpu().numpy())\n",
    "            #val_labels_eval.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "        #val_labels_idx = [np.argmax(tensor) for tensor in val_labels_eval]\n",
    "        #val_accuracy = accuracy_score(val_labels_idx, val_predictions)\n",
    "        \n",
    "        \n",
    "        #print(f\"Epoch {epoch + 1}/{num_epochs},  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be001c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
