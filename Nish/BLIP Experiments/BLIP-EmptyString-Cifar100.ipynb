{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372955fe-ec44-4c9f-8a51-e8ce886a0c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, Image\n",
    "\n",
    "from transformers import BlipForQuestionAnswering, BlipProcessor, BlipConfig, BlipModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7920a9b0-75ee-423a-9b7b-ccdda33fb84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5356f74-5823-4e97-a9aa-0237bcef8b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, image_files, text, processor, num_labels):\n",
    "        self.image_files = image_files\n",
    "        self.text = text\n",
    "        self.processor = processor\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text\n",
    "        image = self.image_files[idx]['img']\n",
    "        label = self.image_files[idx]['fine_label']\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        # encoding = self.processor(image, text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        encoding = self.processor(image, text, return_tensors=\"pt\")\n",
    "\n",
    "        # remove batch dimension\n",
    "        for k,v in encoding.items():\n",
    "            encoding[k] = v.squeeze()\n",
    "        targets = torch.zeros(self.num_labels)\n",
    "        targets[label] = 1\n",
    "        encoding[\"labels\"] = targets\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f9fe6-fb4d-497e-89f9-868c971850c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar100 (/root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f2d497c479438398d015c0562019cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59785229-aebb-414a-99e5-ecf75d4a3ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = dataset[\"train\"].features[\"fine_label\"].names\n",
    "num_labels = len(label_list)\n",
    "\n",
    "config = BlipConfig.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "config.id2label = {str(i): label for i, label in enumerate(label_list)}\n",
    "config.label2id = {label: str(i) for i, label in enumerate(label_list)}\n",
    "config.num_labels = num_labels\n",
    "config.max_length = 1\n",
    "config.text_config.max_length = 1\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "\n",
    "train_dataset = ImageDataset(image_files=dataset[\"train\"], text=\"\", processor=processor, num_labels=num_labels)\n",
    "test_dataset = ImageDataset(image_files=dataset[\"test\"], text=\"\", processor=processor, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d075fe15-aab5-4f41-a245-98dc6015cc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\", config=config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce999c9-d7b9-4b7a-bbc1-d4b569a2be7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  input_ids = [item['input_ids'] for item in batch]\n",
    "  pixel_values = [item['pixel_values'] for item in batch]\n",
    "  attention_mask = [item['attention_mask'] for item in batch]\n",
    "  # token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "  labels = [item['labels'] for item in batch]\n",
    "\n",
    "  # create padded pixel values and corresponding pixel mask\n",
    "  # encoding = processor.feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "  # create new batch\n",
    "  batch = {}\n",
    "  batch['input_ids'] = torch.stack(input_ids)\n",
    "  batch['attention_mask'] = torch.stack(attention_mask)\n",
    "  # batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "  # batch['pixel_values'] = encoding['pixel_values']\n",
    "  # batch['pixel_mask'] = encoding['pixel_mask']\n",
    "  batch['pixel_values'] = torch.stack(pixel_values)\n",
    "  batch['labels'] = torch.stack(labels)\n",
    "  # batch['labels'] = torch.Tensor(labels).type(torch.LongTensor).unsqueeze(1)\n",
    "\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70cfc7e-517f-4e5f-944d-547af369a38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33566460-d37b-4f63-ab84-a04e7055753a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3f2a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2604d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_model = nn.Sequential(\n",
    "    nn.Linear(in_features=model.text_decoder.config.vocab_size, out_features=num_labels, bias=True)\n",
    ")\n",
    "cls_model = cls_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4446838-c178-4f36-ab96-f4111a1360e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/391 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (1) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   0%|          | 1/391 [00:05<35:24,  5.45s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|          | 2/391 [00:08<24:47,  3.82s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|          | 3/391 [00:10<21:09,  3.27s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|          | 4/391 [00:13<19:26,  3.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|▏         | 5/391 [00:16<18:34,  2.89s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 6/391 [00:18<17:59,  2.81s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 7/391 [00:21<17:31,  2.74s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 8/391 [00:23<17:10,  2.69s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 9/391 [00:26<17:05,  2.68s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 10/391 [00:29<16:57,  2.67s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 11/391 [00:31<16:48,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 12/391 [00:34<16:37,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 13/391 [00:36<16:26,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▎         | 14/391 [00:39<16:26,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▍         | 15/391 [00:42<16:20,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▍         | 16/391 [00:44<16:19,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▍         | 17/391 [00:47<16:26,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▍         | 18/391 [00:50<16:29,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▍         | 19/391 [00:52<16:29,  2.66s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▌         | 20/391 [00:55<16:25,  2.66s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▌         | 21/391 [00:58<16:22,  2.66s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▌         | 22/391 [01:00<16:17,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▌         | 23/391 [01:03<16:10,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▌         | 24/391 [01:05<16:02,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▋         | 25/391 [01:08<15:57,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 26/391 [01:11<15:53,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 27/391 [01:13<15:46,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 28/391 [01:16<15:46,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 29/391 [01:18<15:42,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 30/391 [01:21<15:40,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 31/391 [01:24<15:35,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 32/391 [01:26<15:31,  2.59s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 33/391 [01:29<15:32,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▊         | 34/391 [01:31<15:29,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▉         | 35/391 [01:34<15:26,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▉         | 36/391 [01:37<15:23,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▉         | 37/391 [01:39<15:18,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|▉         | 38/391 [01:42<15:18,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|▉         | 39/391 [01:44<15:12,  2.59s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|█         | 40/391 [01:47<15:11,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|█         | 41/391 [01:50<15:11,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  11%|█         | 42/391 [01:52<15:08,  2.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  11%|█         | 43/391 [01:55<15:14,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  11%|█▏        | 44/391 [01:58<15:14,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 45/391 [02:00<15:12,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 46/391 [02:03<15:07,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 47/391 [02:05<15:01,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 48/391 [02:08<14:57,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 49/391 [02:11<14:51,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 50/391 [02:13<14:58,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 51/391 [02:16<14:54,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 52/391 [02:19<14:54,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▎        | 53/391 [02:21<14:52,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▍        | 54/391 [02:24<14:52,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▍        | 55/391 [02:27<14:48,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▍        | 56/391 [02:29<14:41,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▍        | 57/391 [02:32<14:45,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▍        | 58/391 [02:35<14:47,  2.67s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▌        | 59/391 [02:37<14:43,  2.66s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▌        | 60/391 [02:40<14:38,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▌        | 61/391 [02:42<14:29,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▌        | 62/391 [02:45<14:25,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▌        | 63/391 [02:48<14:18,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▋        | 64/391 [02:50<14:23,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 65/391 [02:53<14:23,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 66/391 [02:56<14:20,  2.65s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 67/391 [02:58<14:13,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 68/391 [03:01<14:07,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 69/391 [03:03<14:02,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 70/391 [03:06<14:06,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 71/391 [03:09<14:02,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 72/391 [03:11<13:56,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▊        | 73/391 [03:14<13:57,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▉        | 74/391 [03:17<13:55,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▉        | 75/391 [03:19<13:49,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▉        | 76/391 [03:22<13:44,  2.62s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|█▉        | 77/391 [03:24<13:40,  2.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|█▉        | 78/391 [03:27<13:41,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|██        | 79/391 [03:30<13:41,  2.63s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|██        | 80/391 [03:32<13:40,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██        | 81/391 [03:35<13:37,  2.64s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██        | 82/391 [03:38<13:55,  2.70s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██        | 83/391 [03:41<13:52,  2.70s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██▏       | 84/391 [03:43<13:53,  2.71s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  22%|██▏       | 85/391 [03:46<14:24,  2.82s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  22%|██▏       | 86/391 [03:49<14:09,  2.78s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  22%|██▏       | 87/391 [03:52<14:00,  2.76s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 88/391 [03:55<13:50,  2.74s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 89/391 [03:57<13:41,  2.72s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 90/391 [04:00<13:51,  2.76s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 91/391 [04:03<13:42,  2.74s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▎       | 92/391 [04:05<13:33,  2.72s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▍       | 93/391 [04:08<13:45,  2.77s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▍       | 94/391 [04:11<13:53,  2.81s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▍       | 95/391 [04:14<14:04,  2.85s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▍       | 96/391 [04:17<14:16,  2.90s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▍       | 97/391 [04:20<14:34,  2.97s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▌       | 98/391 [04:23<14:37,  2.99s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▌       | 99/391 [04:27<14:48,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▌       | 100/391 [04:30<14:52,  3.07s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▌       | 101/391 [04:33<14:51,  3.08s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▌       | 102/391 [04:36<14:44,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▋       | 103/391 [04:39<14:45,  3.07s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 104/391 [04:42<14:34,  3.05s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 105/391 [04:45<14:28,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 106/391 [04:48<14:22,  3.03s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 107/391 [04:51<14:16,  3.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 108/391 [04:54<14:12,  3.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 109/391 [04:57<14:17,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 110/391 [05:00<14:11,  3.03s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 111/391 [05:03<14:15,  3.05s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▊       | 112/391 [05:06<14:14,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▉       | 113/391 [05:09<14:09,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▉       | 114/391 [05:12<14:05,  3.05s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▉       | 115/391 [05:15<14:01,  3.05s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|██▉       | 116/391 [05:18<14:02,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|██▉       | 117/391 [05:21<13:53,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|███       | 118/391 [05:24<13:47,  3.03s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|███       | 119/391 [05:27<13:48,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███       | 120/391 [05:30<13:41,  3.03s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███       | 121/391 [05:33<13:36,  3.02s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███       | 122/391 [05:36<13:30,  3.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███▏      | 123/391 [05:39<13:26,  3.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 124/391 [05:42<13:23,  3.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 125/391 [05:46<13:22,  3.02s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 126/391 [05:49<13:31,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 127/391 [05:52<13:23,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  33%|███▎      | 128/391 [05:55<13:25,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  33%|███▎      | 129/391 [05:58<13:16,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  33%|███▎      | 130/391 [06:01<13:12,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▎      | 131/391 [06:04<13:13,  3.05s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▍      | 132/391 [06:07<13:23,  3.10s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▍      | 133/391 [06:10<13:23,  3.11s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▍      | 134/391 [06:13<13:12,  3.08s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▍      | 135/391 [06:16<13:05,  3.07s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▍      | 136/391 [06:19<12:55,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▌      | 137/391 [06:22<12:49,  3.03s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▌      | 138/391 [06:25<12:39,  3.00s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▌      | 139/391 [06:28<12:53,  3.07s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▌      | 140/391 [06:32<13:01,  3.11s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▌      | 141/391 [06:35<12:50,  3.08s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▋      | 142/391 [06:38<12:42,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 143/391 [06:41<12:35,  3.05s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 144/391 [06:44<12:34,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 145/391 [06:47<12:38,  3.08s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 146/391 [06:50<12:28,  3.06s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 147/391 [06:53<12:40,  3.12s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 148/391 [06:56<12:28,  3.08s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 149/391 [06:59<12:15,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 150/391 [07:02<12:08,  3.02s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  39%|███▊      | 151/391 [07:05<12:09,  3.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  39%|███▉      | 152/391 [07:08<12:05,  3.03s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  66%|██████▌   | 259/391 [12:35<06:44,  3.06s/it]"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cls_model.parameters(), lr=6e-4)\n",
    "num_epochs = 30\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.25)\n",
    "\n",
    "best_params = None\n",
    "best_val_accuracy = -1\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    train_predictions = []\n",
    "    train_labels_eval = []\n",
    "    step = 0\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        \n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        outputs = model.generate(**batch)  # N,2\n",
    "        outputs = outputs[:,1]\n",
    "        outputs = nn.functional.one_hot(outputs, num_classes = model.text_decoder.config.vocab_size).type(torch.FloatTensor)\n",
    "        outputs = outputs.to(device)\n",
    "        labels = batch['labels']\n",
    "\n",
    "        outputs_cls = cls_model(outputs)\n",
    "        loss = criterion(outputs_cls, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs_cls, 1)\n",
    "        train_predictions.extend(preds.cpu().numpy())\n",
    "        train_labels_eval.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with open(\"BLIP-EmptyString-C100.txt\", 'a') as f:\n",
    "            f.write(f\"Batch: {step} --- Loss: {loss}\\n\")\n",
    "\n",
    "        total_loss += loss\n",
    "        step += 1\n",
    "            \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels_eval = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        step = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k:v.to(device) for k,v in batch.items()}\n",
    "            \n",
    "            outputs = model.generate(**batch)\n",
    "            outputs = outputs[:,1]\n",
    "            outputs = nn.functional.one_hot(outputs, num_classes = model.text_decoder.config.vocab_size).type(torch.FloatTensor)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            outputs_cls = cls_model(outputs)\n",
    "            _, preds = torch.max(outputs_cls, 1)\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            val_predictions.extend(preds.cpu().numpy())\n",
    "            val_labels_eval.extend(labels.cpu().numpy())\n",
    "\n",
    "            step += 1\n",
    "    \n",
    "    val_labels_idx = [np.argmax(tensor) for tensor in val_labels_eval]\n",
    "    val_accuracy = accuracy_score(val_labels_idx, val_predictions)\n",
    "    \n",
    "    train_labels_idx = [np.argmax(tensor) for tensor in train_labels_eval]\n",
    "    train_accuracy = accuracy_score(train_labels_idx, train_predictions)\n",
    "    \n",
    "    # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Training Acc: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    to_write = f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Training Acc: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n\"\n",
    "    with open(\"BLIP-EmptyString-C100.txt\", 'a') as f:\n",
    "        f.write(to_write)\n",
    "    # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcca965-7b43-47c1-b857-e170a03b9ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
