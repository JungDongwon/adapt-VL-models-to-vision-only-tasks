{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372955fe-ec44-4c9f-8a51-e8ce886a0c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset, Image\n",
    "\n",
    "from transformers import BlipForQuestionAnswering, BlipProcessor, BlipConfig, BlipModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7920a9b0-75ee-423a-9b7b-ccdda33fb84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5356f74-5823-4e97-a9aa-0237bcef8b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, image_files, text, processor, num_labels):\n",
    "        self.image_files = image_files\n",
    "        self.text = text\n",
    "        self.processor = processor\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text\n",
    "        image = self.image_files[idx]['img']\n",
    "        label = self.image_files[idx]['fine_label']\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        \n",
    "        # encoding = self.processor(image, text, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        encoding = self.processor(image, text, return_tensors=\"pt\")\n",
    "\n",
    "        # remove batch dimension\n",
    "        for k,v in encoding.items():\n",
    "            encoding[k] = v.squeeze()\n",
    "        targets = torch.zeros(self.num_labels)\n",
    "        targets[label] = 1\n",
    "        encoding[\"labels\"] = targets\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f9fe6-fb4d-497e-89f9-868c971850c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar100 (/root/.cache/huggingface/datasets/cifar100/cifar100/1.0.0/f365c8b725c23e8f0f8d725c3641234d9331cd2f62919d1381d1baa5b3ba3142)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec46e0121c64616b0fada767f33d211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('cifar100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59785229-aebb-414a-99e5-ecf75d4a3ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_list = dataset[\"train\"].features[\"fine_label\"].names\n",
    "num_labels = len(label_list)\n",
    "\n",
    "config = BlipConfig.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "config.id2label = {str(i): label for i, label in enumerate(label_list)}\n",
    "config.label2id = {label: str(i) for i, label in enumerate(label_list)}\n",
    "config.num_labels = num_labels\n",
    "config.max_length = 1\n",
    "config.text_config.max_length = 1\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "\n",
    "train_dataset = ImageDataset(image_files=dataset[\"train\"], text=\"This is a classification prompt from the cifar10 dataset. Classify the images amongst the classes 'beaver', 'dolphin', 'otter', 'seal', 'whale' ,'aquarium' 'fish', 'flatfish', 'ray', 'shark', 'trout', 'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', 'bottles', 'bowls', 'cans', 'cups', 'plates', 'apples', 'mushrooms', 'oranges', 'pears', 'sweet' 'peppers', 'clock', 'computer' 'keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', 'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', 'bear', 'leopard', 'lion', 'tiger', 'wolf', 'bridge', 'castle', 'house', 'road', 'skyscraper', 'cloud', 'forest', 'mountain', 'plain', 'sea', 'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', 'fox', 'porcupine', 'possum', 'raccoon', 'skunk', 'crab', 'lobster', 'snail', 'spider', 'worm', 'baby', 'boy', 'girl', 'man', 'woman', 'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', 'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', 'maple', 'oak', 'palm', 'pine', 'willow', 'bicycle', 'bus', 'motorcycle', 'pickup' 'truck', 'train', 'lawn'-'mower', 'rocket', 'streetcar', 'tank', 'tractor'.\", processor=processor, num_labels=num_labels)\n",
    "test_dataset = ImageDataset(image_files=dataset[\"test\"], text=\"This is a classification prompt from the cifar10 dataset. Classify the images amongst the classes 'beaver', 'dolphin', 'otter', 'seal', 'whale' ,'aquarium' 'fish', 'flatfish', 'ray', 'shark', 'trout', 'orchids', 'poppies', 'roses', 'sunflowers', 'tulips', 'bottles', 'bowls', 'cans', 'cups', 'plates', 'apples', 'mushrooms', 'oranges', 'pears', 'sweet' 'peppers', 'clock', 'computer' 'keyboard', 'lamp', 'telephone', 'television', 'bed', 'chair', 'couch', 'table', 'wardrobe', 'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach', 'bear', 'leopard', 'lion', 'tiger', 'wolf', 'bridge', 'castle', 'house', 'road', 'skyscraper', 'cloud', 'forest', 'mountain', 'plain', 'sea', 'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo', 'fox', 'porcupine', 'possum', 'raccoon', 'skunk', 'crab', 'lobster', 'snail', 'spider', 'worm', 'baby', 'boy', 'girl', 'man', 'woman', 'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle', 'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel', 'maple', 'oak', 'palm', 'pine', 'willow', 'bicycle', 'bus', 'motorcycle', 'pickup' 'truck', 'train', 'lawn'-'mower', 'rocket', 'streetcar', 'tank', 'tractor'.\", processor=processor, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d075fe15-aab5-4f41-a245-98dc6015cc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\", config=config)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce999c9-d7b9-4b7a-bbc1-d4b569a2be7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "  input_ids = [item['input_ids'] for item in batch]\n",
    "  pixel_values = [item['pixel_values'] for item in batch]\n",
    "  attention_mask = [item['attention_mask'] for item in batch]\n",
    "  # token_type_ids = [item['token_type_ids'] for item in batch]\n",
    "  labels = [item['labels'] for item in batch]\n",
    "\n",
    "  # create padded pixel values and corresponding pixel mask\n",
    "  # encoding = processor.feature_extractor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "\n",
    "  # create new batch\n",
    "  batch = {}\n",
    "  batch['input_ids'] = torch.stack(input_ids)\n",
    "  batch['attention_mask'] = torch.stack(attention_mask)\n",
    "  # batch['token_type_ids'] = torch.stack(token_type_ids)\n",
    "  # batch['pixel_values'] = encoding['pixel_values']\n",
    "  # batch['pixel_mask'] = encoding['pixel_mask']\n",
    "  batch['pixel_values'] = torch.stack(pixel_values)\n",
    "  batch['labels'] = torch.stack(labels)\n",
    "  # batch['labels'] = torch.Tensor(labels).type(torch.LongTensor).unsqueeze(1)\n",
    "\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70cfc7e-517f-4e5f-944d-547af369a38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33566460-d37b-4f63-ab84-a04e7055753a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3f2a0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2604d24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cls_model = nn.Sequential(\n",
    "    nn.Linear(in_features=model.text_decoder.config.vocab_size, out_features=num_labels, bias=True)\n",
    ")\n",
    "cls_model = cls_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4446838-c178-4f36-ab96-f4111a1360e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   0%|          | 0/391 [00:00<?, ?it/s]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   0%|          | 1/391 [00:03<25:36,  3.94s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|          | 2/391 [00:07<25:25,  3.92s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|          | 3/391 [00:11<25:13,  3.90s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|          | 4/391 [00:15<25:07,  3.90s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   1%|▏         | 5/391 [00:19<25:14,  3.92s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 6/391 [00:23<25:01,  3.90s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 7/391 [00:27<25:03,  3.92s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 8/391 [00:31<24:50,  3.89s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   2%|▏         | 9/391 [00:35<24:56,  3.92s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 10/391 [00:39<24:47,  3.90s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 11/391 [00:43<24:49,  3.92s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 12/391 [00:47<24:52,  3.94s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   3%|▎         | 13/391 [00:50<24:47,  3.94s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▎         | 14/391 [00:54<24:50,  3.95s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▍         | 15/391 [00:58<24:52,  3.97s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▍         | 16/391 [01:03<25:03,  4.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   4%|▍         | 17/391 [01:07<24:57,  4.00s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▍         | 18/391 [01:11<25:00,  4.02s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▍         | 19/391 [01:15<24:51,  4.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▌         | 20/391 [01:19<24:57,  4.04s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   5%|▌         | 21/391 [01:23<25:36,  4.15s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▌         | 22/391 [01:28<26:03,  4.24s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▌         | 23/391 [01:32<26:34,  4.33s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▌         | 24/391 [01:37<26:46,  4.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   6%|▋         | 25/391 [01:41<27:09,  4.45s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 26/391 [01:46<27:10,  4.47s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 27/391 [01:50<27:07,  4.47s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 28/391 [01:55<27:05,  4.48s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   7%|▋         | 29/391 [01:59<27:19,  4.53s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 30/391 [02:05<29:29,  4.90s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 31/391 [02:11<31:56,  5.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 32/391 [02:18<34:05,  5.70s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   8%|▊         | 33/391 [02:24<35:16,  5.91s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▊         | 34/391 [02:31<35:50,  6.02s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▉         | 35/391 [02:37<36:10,  6.10s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▉         | 36/391 [02:43<36:05,  6.10s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:   9%|▉         | 37/391 [02:49<36:11,  6.14s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|▉         | 38/391 [02:56<36:27,  6.20s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|▉         | 39/391 [03:02<36:28,  6.22s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|█         | 40/391 [03:08<36:33,  6.25s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  10%|█         | 41/391 [03:14<36:30,  6.26s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  11%|█         | 42/391 [03:21<36:23,  6.26s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  11%|█         | 43/391 [03:27<36:23,  6.28s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  11%|█▏        | 44/391 [03:34<36:41,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 45/391 [03:40<36:25,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 46/391 [03:46<36:11,  6.29s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 47/391 [03:53<36:24,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  12%|█▏        | 48/391 [03:59<36:29,  6.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 49/391 [04:05<36:24,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 50/391 [04:12<36:06,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 51/391 [04:18<35:57,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  13%|█▎        | 52/391 [04:24<35:29,  6.28s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▎        | 53/391 [04:31<35:40,  6.33s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▍        | 54/391 [04:37<35:51,  6.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▍        | 55/391 [04:43<35:16,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  14%|█▍        | 56/391 [04:49<35:10,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▍        | 57/391 [04:56<35:02,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▍        | 58/391 [05:02<35:06,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▌        | 59/391 [05:08<34:54,  6.31s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  15%|█▌        | 60/391 [05:15<35:03,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▌        | 61/391 [05:21<34:59,  6.36s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▌        | 62/391 [05:28<34:43,  6.33s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▌        | 63/391 [05:34<34:40,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  16%|█▋        | 64/391 [05:40<34:27,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 65/391 [05:46<34:20,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 66/391 [05:53<34:17,  6.33s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 67/391 [05:59<34:11,  6.33s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  17%|█▋        | 68/391 [06:05<33:51,  6.29s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 69/391 [06:12<33:37,  6.26s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 70/391 [06:18<33:31,  6.27s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 71/391 [06:24<33:27,  6.27s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  18%|█▊        | 72/391 [06:30<33:27,  6.29s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▊        | 73/391 [06:37<33:44,  6.37s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▉        | 74/391 [06:43<33:30,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▉        | 75/391 [06:50<33:24,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  19%|█▉        | 76/391 [06:57<34:19,  6.54s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|█▉        | 77/391 [07:03<33:48,  6.46s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|█▉        | 78/391 [07:09<33:49,  6.49s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|██        | 79/391 [07:16<33:31,  6.45s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  20%|██        | 80/391 [07:22<33:19,  6.43s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██        | 81/391 [07:28<32:53,  6.37s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██        | 82/391 [07:35<32:33,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██        | 83/391 [07:41<32:35,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  21%|██▏       | 84/391 [07:47<32:12,  6.29s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  22%|██▏       | 85/391 [07:54<32:20,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  22%|██▏       | 86/391 [08:00<32:12,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  22%|██▏       | 87/391 [08:06<32:07,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 88/391 [08:13<32:16,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 89/391 [08:19<32:13,  6.40s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 90/391 [08:25<31:48,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  23%|██▎       | 91/391 [08:32<31:56,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▎       | 92/391 [08:38<31:29,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▍       | 93/391 [08:45<31:34,  6.36s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▍       | 94/391 [08:51<31:27,  6.36s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  24%|██▍       | 95/391 [08:57<31:20,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▍       | 96/391 [09:04<31:24,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▍       | 97/391 [09:10<31:06,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▌       | 98/391 [09:16<31:00,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  25%|██▌       | 99/391 [09:23<31:03,  6.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▌       | 100/391 [09:29<30:46,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▌       | 101/391 [09:36<30:52,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▌       | 102/391 [09:42<30:33,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  26%|██▋       | 103/391 [09:48<30:13,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 104/391 [09:54<30:08,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 105/391 [10:01<30:16,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 106/391 [10:07<29:59,  6.32s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  27%|██▋       | 107/391 [10:13<29:51,  6.31s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 108/391 [10:19<29:29,  6.25s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 109/391 [10:26<29:30,  6.28s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 110/391 [10:32<29:32,  6.31s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  28%|██▊       | 111/391 [10:39<29:34,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▊       | 112/391 [10:45<29:28,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▉       | 113/391 [10:51<29:21,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▉       | 114/391 [10:57<29:07,  6.31s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  29%|██▉       | 115/391 [11:04<29:00,  6.31s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|██▉       | 116/391 [11:11<29:54,  6.52s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|██▉       | 117/391 [11:17<29:16,  6.41s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|███       | 118/391 [11:23<29:09,  6.41s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  30%|███       | 119/391 [11:30<28:50,  6.36s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███       | 120/391 [11:36<28:36,  6.33s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███       | 121/391 [11:42<28:33,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███       | 122/391 [11:49<28:25,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  31%|███▏      | 123/391 [11:55<28:22,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 124/391 [12:01<28:02,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 125/391 [12:07<27:56,  6.30s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 126/391 [12:14<28:06,  6.36s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  32%|███▏      | 127/391 [12:21<28:20,  6.44s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  33%|███▎      | 128/391 [12:27<28:06,  6.41s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  33%|███▎      | 129/391 [12:33<27:51,  6.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  33%|███▎      | 130/391 [12:39<27:35,  6.34s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▎      | 131/391 [12:46<27:31,  6.35s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▍      | 132/391 [12:52<27:34,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▍      | 133/391 [12:59<27:29,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  34%|███▍      | 134/391 [13:05<27:24,  6.40s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▍      | 135/391 [13:12<27:29,  6.44s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▍      | 136/391 [13:18<27:17,  6.42s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▌      | 137/391 [13:25<27:13,  6.43s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  35%|███▌      | 138/391 [13:31<26:53,  6.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▌      | 139/391 [13:37<26:53,  6.40s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▌      | 140/391 [13:44<26:42,  6.39s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▌      | 141/391 [13:50<26:35,  6.38s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  36%|███▋      | 142/391 [13:57<27:24,  6.60s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 143/391 [14:03<26:58,  6.53s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 144/391 [14:10<26:43,  6.49s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 145/391 [14:16<26:20,  6.42s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  37%|███▋      | 146/391 [14:23<26:20,  6.45s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 147/391 [14:29<26:02,  6.40s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 148/391 [14:36<26:19,  6.50s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 149/391 [14:45<29:12,  7.24s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  38%|███▊      | 150/391 [14:51<28:08,  7.01s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  39%|███▊      | 151/391 [14:58<27:21,  6.84s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  39%|███▉      | 152/391 [15:04<26:51,  6.74s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  39%|███▉      | 153/391 [15:10<26:12,  6.61s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  39%|███▉      | 154/391 [15:17<25:49,  6.54s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  40%|███▉      | 155/391 [15:23<25:25,  6.46s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  40%|███▉      | 156/391 [15:29<25:22,  6.48s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  40%|████      | 157/391 [15:36<25:05,  6.43s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  40%|████      | 158/391 [15:42<25:01,  6.44s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  41%|████      | 159/391 [15:49<24:53,  6.44s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  41%|████      | 160/391 [15:55<24:46,  6.43s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  41%|████      | 161/391 [16:01<24:10,  6.31s/it]Input length of input_ids is 1, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "Epoch 1/30:  41%|████▏     | 162/391 [16:07<24:01,  6.29s/it]"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cls_model.parameters(), lr=6e-4)\n",
    "num_epochs = 30\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.25)\n",
    "\n",
    "best_params = None\n",
    "best_val_accuracy = -1\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    train_predictions = []\n",
    "    train_labels_eval = []\n",
    "    step = 0\n",
    "    \n",
    "    for batch in tqdm.tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "        \n",
    "        batch = {k:v.to(device) for k,v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        outputs = model.generate(**batch)  # N,2\n",
    "        outputs = outputs[:,1]\n",
    "        outputs = nn.functional.one_hot(outputs, num_classes = model.text_decoder.config.vocab_size).type(torch.FloatTensor)\n",
    "        outputs = outputs.to(device)\n",
    "        labels = batch['labels']\n",
    "\n",
    "        outputs_cls = cls_model(outputs)\n",
    "        loss = criterion(outputs_cls, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs_cls, 1)\n",
    "        train_predictions.extend(preds.cpu().numpy())\n",
    "        train_labels_eval.extend(labels.cpu().numpy())\n",
    "        \n",
    "        with open(\"BLIP-Mahesh-C100.txt\", 'a') as f:\n",
    "            f.write(f\"Batch: {step} --- Loss: {loss}\\n\")\n",
    "\n",
    "        total_loss += loss\n",
    "        step += 1\n",
    "            \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_predictions = []\n",
    "    val_labels_eval = []\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        step = 0\n",
    "\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k:v.to(device) for k,v in batch.items()}\n",
    "            \n",
    "            outputs = model.generate(**batch)\n",
    "            outputs = outputs[:,1]\n",
    "            outputs = nn.functional.one_hot(outputs, num_classes = model.text_decoder.config.vocab_size).type(torch.FloatTensor)\n",
    "            outputs = outputs.to(device)\n",
    "\n",
    "            outputs_cls = cls_model(outputs)\n",
    "            _, preds = torch.max(outputs_cls, 1)\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            val_predictions.extend(preds.cpu().numpy())\n",
    "            val_labels_eval.extend(labels.cpu().numpy())\n",
    "\n",
    "            step += 1\n",
    "    \n",
    "    val_labels_idx = [np.argmax(tensor) for tensor in val_labels_eval]\n",
    "    val_accuracy = accuracy_score(val_labels_idx, val_predictions)\n",
    "    \n",
    "    train_labels_idx = [np.argmax(tensor) for tensor in train_labels_eval]\n",
    "    train_accuracy = accuracy_score(train_labels_idx, train_predictions)\n",
    "    \n",
    "    # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Training Acc: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    to_write = f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Training Acc: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n\"\n",
    "    with open(\"BLIP-Mahesh-C100.txt\", 'a') as f:\n",
    "        f.write(to_write)\n",
    "    # print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
